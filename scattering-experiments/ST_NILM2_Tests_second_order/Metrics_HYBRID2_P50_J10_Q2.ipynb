{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pW31lJiMh35dKTLd-l7VojatBj77pQ3d","timestamp":1682432342965},{"file_id":"13uhX79D6PgKWzXQKp5fcT0tKZoywxZE8","timestamp":1680101774134},{"file_id":"1Nrq_5H_oXz-1d8Bto47-lxldJ8SIhpaA","timestamp":1680099209489},{"file_id":"1yNN-A1tW9R7xnKc_QdeHB3aHytB-kHFt","timestamp":1680029210436},{"file_id":"1sj06Iho_sjz6h2DUSDVEyWW0nLaYmtNx","timestamp":1680013327133},{"file_id":"1h8tyEde63QDSaf66cKZdrKk8QmqCz0xR","timestamp":1680005993229},{"file_id":"1-6q22cHiMGZGL7vh_Y6F4v3E6aphJ2dV","timestamp":1654529821350},{"file_id":"1GPqs1izycmkDVD5n6GgSy1DtCURypzT-","timestamp":1654528596832},{"file_id":"1cuqu_GSk66c2bg-i1YmHwkUeW1ujLhUT","timestamp":1654524075712},{"file_id":"1T5zGKNA-nI68K9Wru6qdpYuKmA9d7qY-","timestamp":1654518356066},{"file_id":"1McGSyXvSnyJ8YUkjg-VKG-_JClPFZLDi","timestamp":1654384652209},{"file_id":"1xzknJx-Ieeb7IL4VSc89fLJDhnesCdBS","timestamp":1654384467028},{"file_id":"1dY148WyRmZsJ0XJNHdUPrwCtYpDq6lk9","timestamp":1654286964737},{"file_id":"1qdcwiRqt2GqCt4IxdpCN6kRtMXvE-WGm","timestamp":1653344321268},{"file_id":"18iAYtreB5QrJDQxsqpXMLxtiA3idSr70","timestamp":1653342728047},{"file_id":"1yql6BpIjDRJJ_LTkNZP2SFjT7eqsT5R7","timestamp":1652320412957},{"file_id":"1RcUWqH9uz-xOBojM5MvbpaOd6izBxGsE","timestamp":1644124111506},{"file_id":"1Zr-Zo-H7PvannY2sqxQ4e8fEUHuCYBN-","timestamp":1635626859392},{"file_id":"https://github.com/LucasNolasco/DeepDFML-NILM/blob/master/notebooks/metrics_notebook.ipynb","timestamp":1625700111727}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"metadata":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-GQaSQNQQvbo"},"source":["# Metrics\n","\n","Evaluates a trained model accordingly to the metrics specified on the paper"]},{"cell_type":"code","metadata":{"id":"YCTCtekCQyv0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680102807586,"user_tz":180,"elapsed":29625,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"d5ead627-929d-4644-f8d5-8e402e05fbd5"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install tensorflow==2.4.0\n","!pip install keras==2.4.0\n","!pip install kymatio\n","!pip install tqdm\n","!pip install iterative-stratification"],"metadata":{"id":"8RYHVHGDHAdo","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1680103198004,"user_tz":180,"elapsed":390425,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"f555750c-739a-44a5-f62d-b6594fac1f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.4.0 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.4.0\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.4.0\n","  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.2/170.2 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.0) (1.10.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras==2.4.0) (6.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.0) (1.22.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras==2.4.0) (3.8.0)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.0) (2.11.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (15.0.6.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.31.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.51.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (23.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.11.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.4.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.11.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.16.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.13,>=2.12\n","  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (23.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.2.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl (498.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.19.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (67.6.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.8.3-cp39-cp39-manylinux2010_x86_64.whl (498.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.5/498.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.2-cp39-cp39-manylinux2010_x86_64.whl (498.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.1-cp39-cp39-manylinux2010_x86_64.whl (498.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.4-cp39-cp39-manylinux2010_x86_64.whl (496.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.1/496.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.40.0)\n","  Downloading tensorflow-2.7.3-cp39-cp39-manylinux2010_x86_64.whl (495.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.6/495.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.2-cp39-cp39-manylinux2010_x86_64.whl (495.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.6/495.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.1-cp39-cp39-manylinux2010_x86_64.whl (495.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.2/495.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.5-cp39-cp39-manylinux2010_x86_64.whl (464.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.3/464.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.4-cp39-cp39-manylinux2010_x86_64.whl (464.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.3/464.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.3-cp39-cp39-manylinux2010_x86_64.whl (463.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.9/463.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.2-cp39-cp39-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.1-cp39-cp39-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting tensorflow-estimator<2.7\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.9/462.9 KB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting six~=1.15.0\n","  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.6.0-cp39-cp39-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.5.3-cp39-cp39-manylinux2010_x86_64.whl (460.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.4/460.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio~=1.34.0\n","  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.9.1\n","  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py\n","  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor~=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.27.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.2.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.16.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.4.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (6.1.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.2.2)\n","Building wheels for collected packages: termcolor, wrapt\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=dd0b605bfe8887fd0b4261422cea04ba875bc8e265569f55ea55fa9902818431\n","  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75943 sha256=d879ca92158fbd75d333f7b1b232c3fa4aa74603aeb8be525ed47dea7a1f1404\n","  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n","Successfully built termcolor wrapt\n","Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, flatbuffers, six, numpy, keras-preprocessing, h5py, grpcio, absl-py, tensorflow, keras\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.15.0\n","    Uninstalling wrapt-1.15.0:\n","      Successfully uninstalled wrapt-1.15.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.2.0\n","    Uninstalling termcolor-2.2.0:\n","      Successfully uninstalled termcolor-2.2.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.11.0\n","    Uninstalling tensorflow-estimator-2.11.0:\n","      Successfully uninstalled tensorflow-estimator-2.11.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.3.3\n","    Uninstalling flatbuffers-23.3.3:\n","      Successfully uninstalled flatbuffers-23.3.3\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.8.0\n","    Uninstalling h5py-3.8.0:\n","      Successfully uninstalled h5py-3.8.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.51.3\n","    Uninstalling grpcio-1.51.3:\n","      Successfully uninstalled grpcio-1.51.3\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.11.0\n","    Uninstalling tensorflow-2.11.0:\n","      Successfully uninstalled tensorflow-2.11.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.11.0\n","    Uninstalling keras-2.11.0:\n","      Successfully uninstalled keras-2.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","pydantic 1.10.7 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","optax 0.1.4 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","matplotlib 3.7.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.19.5 which is incompatible.\n","librosa 0.10.0.post2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n","jaxlib 0.4.6+cuda11.cudnn86 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.4.6 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n","google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n","flax 0.6.7 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","chex 0.1.6 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n","bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","astropy 5.2.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","arviz 0.15.1 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\n","arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 grpcio-1.34.1 h5py-3.1.0 keras-2.4.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 numpy-1.19.5 six-1.15.0 tensorflow-2.5.3 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kymatio\n","  Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kymatio) (23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from kymatio) (1.19.5)\n","Collecting configparser\n","  Downloading configparser-5.3.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from kymatio) (1.4.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from kymatio) (1.10.1)\n","Installing collected packages: configparser, kymatio\n","Successfully installed configparser-5.3.0 kymatio-0.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["configparser"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (1.1.1)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.7\n"]}]},{"cell_type":"code","metadata":{"id":"ER7854z7Qvbw","executionInfo":{"status":"ok","timestamp":1680103227936,"user_tz":180,"elapsed":29948,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2a847cf-5f73-488f-a0be-aee442e574c5"},"source":["import sys\n","sys.path.append(\"drive/MyDrive/Scattering_Novo/src\")\n","\n","# Scattering Parameters\n","J=10\n","Q=2\n","\n","\n","import numpy as np\n","from sklearn.metrics import f1_score, precision_score, recall_score, multilabel_confusion_matrix \n","from sklearn.model_selection import train_test_split\n","from ModelHandler import ModelHandler\n","import pickle\n","import h5py\n","from sklearn.metrics import f1_score, precision_score, recall_score     \n","from tqdm import tqdm\n","import tensorflow as tf\n","\n","\n","configs = {\n","    \"N_GRIDS\": 5, \n","    \"SIGNAL_BASE_LENGTH\": 12800, \n","    \"N_CLASS\": 26, \n","    \"USE_NO_LOAD\": False, \n","    \"USE_HAND_AUGMENTATION\": False,\n","    \"MARGIN_RATIO\": 0.15, \n","    \"DATASET_PATH\": \"drive/MyDrive/Scattering_Novo/dataset_original/Synthetic_Full_iHall.hdf5\",\n","    \"TRAIN_SIZE\": 0.9,\n","    \"FOLDER_PATH\": \"drive/MyDrive/DeSpaWN-main/extracted_features/without_data_augmentation/Full_Dataset/\", \n","    \"FOLDER_DATA_PATH\": \"drive/MyDrive/DeSpaWN-main/extracted_features/without_data_augmentation/Full_Dataset/\", \n","    \"TESTS_FOLDER\": 'drive/MyDrive/Scattering_Novo/results_second_order/without_data_augmentation/',\n","    \"FEATURES_FILE_NAME\": \"features.mat\",\n","    \"N_EPOCHS_TRAINING\": 500,\n","    \"PERCENTUAL\": 0.50,\n","    \"INITIAL_EPOCH\": 0,\n","    \"TOTAL_MAX_EPOCHS\": 5000,\n","    \"SNRdb\": None # Nível de ruído em db\n","}\n","\n","folderPath = 'drive/MyDrive/Scattering_Novo/results_second_order/' + 'Hybrid2_P' + str(int(configs[\"PERCENTUAL\"]*100)) + '_J' + str(J) + '_Q' + str(Q) + '/'\n","#folderPath = configs[\"TESTS_FOLDER\"] + 'Hybrid_P' + str(int(configs[\"PERCENTUAL\"]*100)) + '_J' + str(J) + '_Q' + str(Q) + '/'\n","folderDataPath = configs[\"FOLDER_DATA_PATH\"]\n","signalBaseLength = configs[\"SIGNAL_BASE_LENGTH\"]\n","ngrids = configs[\"N_GRIDS\"]\n","trainSize = configs[\"TRAIN_SIZE\"]\n","\n","dict_data = pickle.load(open(folderDataPath + \"data.p\", \"rb\")) # Load data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"markdown","metadata":{"id":"vomuxuyDZ9Pe"},"source":["## Choose best performing model\n","\n","At this point, the model with best performance under the validation set is chosen.\n","\n","In order to make this choice, the average between f1 macro is verified.\n","\n","$$\n","F_1 = \\frac{F1_{ON} + F1_{OFF} + F1_{NO EVENT}}{3}\n","$$"]},{"cell_type":"code","metadata":{"id":"uwe09boZZ81Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103506906,"user_tz":180,"elapsed":278988,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"90c4a789-6fb6-4508-fe2f-f856315969cb"},"source":["def choose_model(dict_data, folderPath):\n","    from tqdm import tqdm\n","    from sklearn.preprocessing import MaxAbsScaler\n","    from sklearn.metrics import f1_score, precision_score, recall_score   \n","    from PostProcessing import PostProcessing\n","\n","    scattering_extract = ModelHandler.loadModel(folderPath + 'scattering_model.h5') # Load scattering model\n","\n","    threshold = 0.5\n","    f1_macro, f1_micro = [], []\n","    for fold in tqdm(range(1, 11)):\n","        foldFolderPath = folderPath + str(fold) + \"/\"\n","        \n","        train_index = np.load(foldFolderPath + \"train_index.npy\")\n","        validation_index = np.load(foldFolderPath + \"validation_index.npy\")\n","\n","        bestModel = ModelHandler.loadModel(foldFolderPath + \"model_without_detection.h5\", type_weights=None) # Load model\n","\n","        scaler = MaxAbsScaler()\n","        scaler.fit(np.squeeze(dict_data[\"x_train\"][train_index], axis=2))\n","        x_validation = np.expand_dims(scaler.transform(np.squeeze(dict_data[\"x_train\"][validation_index], axis=2)), axis=2)\n","\n","        x_validation_type, x_validation_class = scattering_extract.predict(x_validation)\n","\n","\n","        transformer = MaxAbsScaler().fit(x_validation_type)\n","        x_validation_type = transformer.transform(x_validation_type)\n","\n","        transformer = MaxAbsScaler().fit(x_validation_class)\n","        x_validation_class = transformer.transform(x_validation_class)\n","\n","\n","        final_prediction = []\n","        final_groundTruth = []\n","        for xi, xi_nd, yclass, ytype in zip(x_validation_type, x_validation_class, dict_data[\"y_train\"][\"classification\"][validation_index], dict_data[\"y_train\"][\"type\"][validation_index]):\n","          \n","            pred = bestModel.predict([np.expand_dims(xi, axis=0),np.expand_dims(xi_nd, axis=0)])\n","            prediction = np.max(pred[1][0],axis=0) # Withou detection, the first index must be one (Related to classification)\n","            groundTruth = np.max(yclass,axis=0)\n","\n","            final_prediction.append(prediction)\n","            final_groundTruth.append(groundTruth) \n","\n","            del xi, yclass, ytype\n","\n","        event_type = np.min(np.argmax(dict_data[\"y_train\"][\"type\"][validation_index], axis=2), axis=1)\n","\n","        final_groundTruth = np.array(final_groundTruth)\n","        final_prediction = np.array(final_prediction)\n","    \n","        f1_macro.append([f1_score(final_groundTruth[event_type == 0] > threshold, final_prediction[event_type == 0] > threshold, average='macro', zero_division=0), \n","                         f1_score(final_groundTruth[event_type == 1] > threshold, final_prediction[event_type == 1] > threshold, average='macro', zero_division=0)])\n","        print(f\"Fold {fold}: F1 Macro avg: {np.average(f1_macro[-1]) * 100:.1f}\") \n","\n","    return np.argmax(np.average(f1_macro, axis=1)) + 1\n","\n","fold = choose_model(dict_data, folderPath)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"," 10%|█         | 1/10 [00:34<05:10, 34.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 1: F1 Macro avg: 78.9\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [00:57<03:42, 27.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 2: F1 Macro avg: 74.1\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [01:20<02:59, 25.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 3: F1 Macro avg: 71.2\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [01:45<02:31, 25.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 4: F1 Macro avg: 71.3\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [02:11<02:07, 25.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 5: F1 Macro avg: 79.4\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [02:35<01:40, 25.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 6: F1 Macro avg: 70.3\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [02:59<01:14, 24.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 7: F1 Macro avg: 61.5\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [03:28<00:52, 26.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 8: F1 Macro avg: 69.4\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [03:57<00:26, 26.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 9: F1 Macro avg: 73.6\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [04:27<00:00, 26.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Fold 10: F1 Macro avg: 80.4\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"sqYMsQ-oQvb1"},"source":["## Evaluates the identification\n","\n","This step generates a dict with the ground truth and the prediction for each test example"]},{"cell_type":"code","metadata":{"id":"WQDY22oqQvb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103575286,"user_tz":180,"elapsed":68387,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"106729f8-95d7-4799-e145-2d3d9cf1e867"},"source":["from tqdm import tqdm\n","from sklearn.preprocessing import MaxAbsScaler\n","\n","foldFolderPath = folderPath + str(fold) + \"/\"\n","\n","train_index = np.load(foldFolderPath + \"train_index.npy\")\n","validation_index = np.load(foldFolderPath + \"validation_index.npy\")\n","\n","bestModel = ModelHandler.loadModel(foldFolderPath + \"model_without_detection.h5\", type_weights=None) # Load model\n","\n","scattering_extract = ModelHandler.loadModel(folderPath + 'scattering_model.h5')\n","\n","scaler = MaxAbsScaler()\n","scaler.fit(np.squeeze(dict_data[\"x_train\"][train_index], axis=2))\n","x_train = np.expand_dims(scaler.transform(np.squeeze(dict_data[\"x_train\"][train_index], axis=2)), axis=2)\n","x_validation = np.expand_dims(scaler.transform(np.squeeze(dict_data[\"x_train\"][validation_index], axis=2)), axis=2)\n","x_test = np.expand_dims(scaler.transform(np.squeeze(dict_data[\"x_test\"], axis=2)), axis=2)\n","\n","\n","x_test_type, x_test_class = scattering_extract.predict(x_test)\n","\n","\n","transformer = MaxAbsScaler().fit(x_test_type)\n","x_test_type = transformer.transform(x_test_type)\n","        \n","transformer = MaxAbsScaler().fit(x_test_class)\n","x_test_class = transformer.transform(x_test_class)\n","\n","\n","final_prediction = []\n","final_groundTruth = []\n","for xi, xi_nd, yclass, ytype in zip(x_test_type, x_test_class, dict_data[\"y_test\"][\"classification\"], dict_data[\"y_test\"][\"type\"]):\n","    pred = bestModel.predict([np.expand_dims(xi, axis=0),np.expand_dims(xi_nd, axis=0)])\n","    prediction = np.max(pred[1][0],axis=0)\n","    groundTruth = np.max(yclass,axis=0)\n","\n","    final_prediction.append(prediction)\n","    final_groundTruth.append(groundTruth) \n","\n","    del xi, yclass, ytype\n","\n","y = {}\n","y[\"true\"] = final_groundTruth.copy()\n","y[\"pred\"] = final_prediction.copy()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"markdown","metadata":{"id":"usqx6Z-iQvb7"},"source":["### F1 Score\n","\n","#### F1 Macro:\n","$$\n","\\begin{gather*}\n","F1_{Macro} = \\frac{1}{Y} \\sum_{i=1}^{Y} \\frac{2 \\cdot tp_i}{2 \\cdot tp_i + fp_i + fn_i}\n","\\end{gather*}\n","$$\n","\n","#### F1 Micro:\n","$$\n","\\begin{gather*}\n","F1_{Micro} = \\frac{2 \\cdot \\sum_{i=1}^{Y} tp_i}{\\sum_{i=1}^{Y} 2 \\cdot tp_i + fp_i + fn_i}\n","\\end{gather*}\n","$$\n","\n","- $tp_i$: True positives classifications for appliance $i$\n","- $fp_i$: False positives classifications for appliance $i$\n","- $fn_i$: False negatives classifications for appliance $i$"]},{"cell_type":"code","metadata":{"id":"AP4MWwFLQvb9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103575288,"user_tz":180,"elapsed":28,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"27c8e3fb-e0f5-4067-a479-434fdb481646"},"source":["from sklearn.metrics import f1_score\n","\n","threshold = 0.5\n","f1_macro = f1_score(np.array(y[\"true\"]) > threshold, np.array(y[\"pred\"]) > threshold, average='macro')\n","f1_micro = f1_score(np.array(y[\"true\"]) > threshold, np.array(y[\"pred\"]) > threshold, average='micro')\n","\n","print(f\"Fold {fold} - F1 Macro: {f1_macro * 100:.1f}, F1 Micro: {f1_micro * 100:.1f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 10 - F1 Macro: 55.0, F1 Micro: 58.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"QJVFvT3LQvcA"},"source":["### Accuracy (ACC)\n","\n","$$\n","\\begin{gather*}\n","ACC_i = \\frac{CCE_i}{TNE_i} \\\\ \\\\\n","ACC = \\frac{1}{Y} \\sum_{i = 1}^{Y} ACC_i\n","\\end{gather*}\n","$$\n","\n","- $ACC_i$: Accuracy for appliance $i$\n","- $CCE_i$: Load connected successfully identified\n","- $TNE_i$: Total of connected events"]},{"cell_type":"code","metadata":{"id":"KQzNt8lTQvcD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103575289,"user_tz":180,"elapsed":26,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"067516d6-df8e-46cc-d1cd-316cc22ff43d"},"source":["threshold = 0.5\n","\n","correct_on = np.zeros((26,1))\n","total_on = np.zeros((26,1))\n","correct_off = np.zeros((26,1))\n","total_off = np.zeros((26,1))\n","correct_no_event = np.zeros((26,1))\n","total_no_event = np.zeros((26,1))\n","\n","for ytype, ytrue, ypred in zip(dict_data[\"y_test\"][\"type\"], y[\"true\"], y[\"pred\"]):\n","    event_type = np.min(np.argmax(ytype, axis=1))\n","    if event_type == 0:\n","        correct_on[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n","        total_on[ytrue > threshold] += 1\n","    elif event_type == 1:\n","        correct_off[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n","        total_off[ytrue > threshold] += 1\n","    else:\n","        correct_no_event[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n","        total_no_event[ytrue > threshold] += 1\n","\n","acc_on = 100 * np.average(np.nan_to_num(correct_on/total_on))\n","acc_off = 100 * np.average(np.nan_to_num(correct_off/total_off))\n","acc_no_event = 100 * np.average(np.nan_to_num(correct_no_event/total_no_event))\n","acc_total = 100 * np.average(np.nan_to_num((correct_on + correct_off + correct_no_event)/(total_on + total_off + total_no_event)))\n","\n","print(f\"Fold {fold} - Acc on: {acc_on:.1f}, Acc off: {acc_off:.1f}, Acc no event: {acc_no_event:.1f} Acc total: {acc_total:.1f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 10 - Acc on: 50.4, Acc off: 56.5, Acc no event: 0.0 Acc total: 55.6\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-6293edaa4ae2>:23: RuntimeWarning: invalid value encountered in true_divide\n","  acc_off = 100 * np.average(np.nan_to_num(correct_off/total_off))\n","<ipython-input-7-6293edaa4ae2>:24: RuntimeWarning: invalid value encountered in true_divide\n","  acc_no_event = 100 * np.average(np.nan_to_num(correct_no_event/total_no_event))\n"]}]},{"cell_type":"markdown","metadata":{"id":"LbFz4ZTJQvcH"},"source":["## Detection Metrics\n","\n","### D\n","$$\n","\\begin{gather*}\n","D = \\frac{ \\sum_{i=1}^{A} |d(i) - ev(i)|}{A}\n","\\end{gather*}\n","$$\n","\n","- `A`: Total of events correctly detected ($\\pm$ 10 semi cycles tolerance)\n","- `d(i)`: Detection for appliance $i$\n","- `ev(i)`: Ground truth detection for appliance $i$\n","\n","## PC\n","\n","$$\n","\\begin{gather*}\n","PC = \\frac{A}{N}\n","\\end{gather*}\n","$$\n","\n","- `A`: Total of events correctly detected ($\\pm$ 10 semi cycles tolerance)\n","- `N`: Total of events"]},{"cell_type":"code","metadata":{"id":"LNHCZt9zQvcJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103633732,"user_tz":180,"elapsed":58464,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"df613466-67b3-4d7a-8f4d-285cba65e63f"},"source":["from PostProcessing import PostProcessing\n","from DataHandler import DataHandler\n","\n","postProcessing = PostProcessing(configs=configs)\n","dataHandler = DataHandler(configs=configs)\n","\n","general_qtd_test = dict_data[\"y_test\"][\"group\"]\n","\n","foldFolderPath = folderPath + str(fold) + \"/\"\n","\n","train_index = np.load(foldFolderPath + \"train_index.npy\")\n","\n","bestModel = ModelHandler.loadModel(foldFolderPath + \"model_without_detection.h5\", type_weights=None) # Load model\n","\n","scaler = MaxAbsScaler()\n","scaler.fit(np.squeeze(dict_data[\"x_train\"][train_index], axis=2))\n","x_test = np.expand_dims(scaler.transform(np.squeeze(dict_data[\"x_test\"], axis=2)), axis=2)\n","x_test_type, x_test_class = scattering_extract.predict(x_test)\n","\n","\n","transformer = MaxAbsScaler().fit(x_test_type)\n","x_test_type = transformer.transform(x_test_type)\n","        \n","transformer = MaxAbsScaler().fit(x_test_class)\n","x_test_class = transformer.transform(x_test_class)\n","\n","\n","print(f\"-------------- FOLD {fold} ---------------\")\n","pcMetric = postProcessing.checkModel2(bestModel, x_test_type, x_test_class, dict_data[\"y_test\"], general_qtd=general_qtd_test, print_error=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- FOLD 10 ---------------\n","Total time: 34.02501498599872, Average Time: 0.04045780616646697\n","LIT-SYN-1 PCmetric: (0.9777777777777777, 0.9736842105263158, 0.9759036144578314)\n","LIT-SYN-2 PCmetric: (0.9197080291970803, 0.8623188405797102, 0.8909090909090909)\n","LIT-SYN-3 PCmetric: (0.8926174496644296, 0.9182389937106918, 0.9058441558441559)\n","LIT-SYN-8 PCmetric: (0.8372093023255814, 0.6853932584269663, 0.76)\n","LIT-SYN-All PCmetric: (0.8992805755395683, 0.8561320754716981, 0.8775267538644471)\n"]}]},{"cell_type":"code","source":["pcMetric\n","\n","pc_on = pcMetric[4][0]\n","pc_off = pcMetric[4][1]\n","pc_all = pcMetric[4][2]"],"metadata":{"id":"RnWzpFITDgsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving the Results\n","\n","import tables\n","import numpy as np\n","\n","row = [acc_on*0.01, acc_off*0.01, acc_total*0.01, f1_macro, f1_micro, pc_on, pc_off, pc_all]\n","\n","print(np.array(row))\n","\n","\n"],"metadata":{"id":"AHvkiN0CBava","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103633733,"user_tz":180,"elapsed":25,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"e7d0be7f-525a-48f0-e3a1-a7c57877ab60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.50372022 0.56513693 0.55647121 0.54989397 0.58356417 0.89928058\n"," 0.85613208 0.87752675]\n"]}]},{"cell_type":"code","source":["fold"],"metadata":{"id":"THle5BPs_2ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680103633733,"user_tz":180,"elapsed":23,"user":{"displayName":"Everton Aguiar","userId":"11563655119343855860"}},"outputId":"a184a46d-0082-4fb2-9a2a-1da4d87768ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":[],"metadata":{"id":"HcyMNjZfDHEa"},"execution_count":null,"outputs":[]}]}