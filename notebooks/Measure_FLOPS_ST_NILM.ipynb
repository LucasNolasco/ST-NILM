{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Measure_FLOPS_ST_NILM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.0\n",
        "!pip install keras==2.4.0\n",
        "!pip install kymatio\n",
        "!pip install tqdm\n",
        "!pip install iterative-stratification\n",
        "!pip install scikit-multilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N0MGCNSBsMHR",
        "outputId": "1e852bff-941f-493b-c105-06524b384f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 47.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68716 sha256=b9434c9ea435f9e8f5ae57e97394e0c55c3a50b25237ff750d1365f9efdccbd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.4.0\n",
            "  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.13)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.8.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.37.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.2.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kymatio\n",
            "  Downloading kymatio-0.2.1-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kymatio) (21.3)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.19.5)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kymatio) (3.0.9)\n",
            "Installing collected packages: configparser, kymatio\n",
            "Successfully installed configparser-5.2.0 kymatio-0.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 3.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-90s9j6sJ-e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from absl import app, flags\n",
        "from easydict import EasyDict\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z42y6taXsP0W",
        "outputId": "a6e0c5f2-a734-44fb-d54c-e3e37cb56c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append(\"drive/MyDrive/Scattering_Novo/src\")\n",
        "from DataHandler import DataHandler\n",
        "from ModelHandler import ModelHandler\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "\n",
        " \n",
        "configs = {\n",
        "    \"N_GRIDS\": 5, \n",
        "    \"SIGNAL_BASE_LENGTH\": 12800, \n",
        "    \"N_CLASS\": 26, \n",
        "    \"USE_NO_LOAD\": False, \n",
        "    \"USE_HAND_AUGMENTATION\": False,\n",
        "    \"MARGIN_RATIO\": 0.15, \n",
        "    \"DATASET_PATH\": \"drive/MyDrive/YOLO_NILM/Synthetic_Full_iHall.hdf5\",\n",
        "    \"TRAIN_SIZE\": 0.9,\n",
        "    \"FOLDER_PATH\": \"drive/MyDrive/Scattering_Novo/tmp/DIFDUAL/tests/AND/AND100_4/\", \n",
        "    \"FOLDER_DATA_PATH\": \"drive/MyDrive/Scattering_Novo/tmp/Without_Detection_Without_HAND/ND100/\", \n",
        "    \"N_EPOCHS_TRAINING\": 5000,\n",
        "    \"PERCENTUAL\": [1],\n",
        "    \"INITIAL_EPOCH\": 0,\n",
        "    \"TOTAL_MAX_EPOCHS\": 5000,\n",
        "    \"SNRdb\": None # Nível de ruído em db\n",
        "}\n",
        "\n",
        "def freeze(model, task_name='classification'):\n",
        "    for layer in model.layers:\n",
        "        if task_name in layer.name:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "\n",
        "    for layer in model.layers:\n",
        "        print(layer.name, layer.trainable)\n",
        "\n",
        "    return model\n",
        "\n",
        "def calculating_class_weights(y_true):\n",
        "    '''\n",
        "        Source: https://stackoverflow.com/questions/48485870/multi-label-classification-with-class-weights-in-keras\n",
        "    '''\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    number_dim = np.shape(y_true)[1]\n",
        "    weights = np.empty([number_dim, 2])\n",
        "    for i in range(number_dim):\n",
        "        weights[i] = compute_class_weight(class_weight='balanced', classes=[0.,1.], y=y_true[:, i])\n",
        "    return weights\n",
        "\n",
        "\n",
        "def reduce_dataset(X_all,ydet_all,ytype_all,yclass_all,percentual):\n",
        "    import numpy as np\n",
        "    max_index = int(percentual*X_all.shape[0])\n",
        "    np.random.seed(100)\n",
        "    index = np.random.randint(max_index,size=(max_index-1))\n",
        "    X_all = X_all[index]\n",
        "    ydet_all = ydet_all[index]\n",
        "    ytype_all = ytype_all[index]\n",
        "    yclass_all = yclass_all[index]\n",
        "\n",
        "    return X_all,ydet_all,ytype_all,yclass_all\n",
        "\n",
        "ngrids = configs[\"N_GRIDS\"]\n",
        "signalBaseLength = configs[\"SIGNAL_BASE_LENGTH\"]\n",
        "trainSize = configs[\"TRAIN_SIZE\"]\n",
        "folderDataPath = configs[\"FOLDER_DATA_PATH\"]\n",
        " \n",
        "dataHandler = DataHandler(configs)\n",
        "\n",
        "\n",
        "if not os.path.isfile(folderDataPath + \"data.p\"):\n",
        "    print(\"Sorted data not found, creating new file...\")\n",
        "    x, ydet, yclass, ytype, ygroup = dataHandler.loadData(hand_augmentation=configs[\"USE_HAND_AUGMENTATION\"], SNR=configs[\"SNRdb\"])\n",
        "    print(\"Data loaded\")\n",
        "\n",
        "    data_mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    strat_classes = np.max(yclass, axis=1)\n",
        "    train_index, test_index = next(data_mskf.split(x, strat_classes))\n",
        "\n",
        "    y_train = {\n",
        "        \"detection\": ydet[train_index], \n",
        "        \"type\": ytype[train_index], \n",
        "        \"classification\": yclass[train_index], \n",
        "        \"group\": ygroup[train_index]\n",
        "    }\n",
        "    \n",
        "    y_test = {\n",
        "        \"detection\": ydet[test_index], \n",
        "        \"type\": ytype[test_index], \n",
        "        \"classification\": yclass[test_index], \n",
        "        \"group\": ygroup[test_index]\n",
        "    }\n",
        "    \n",
        "    dict_data = {\n",
        "        \"x_train\": x[train_index], \n",
        "        \"x_test\": x[test_index], \n",
        "        \"y_train\": y_train, \n",
        "        \"y_test\": y_test\n",
        "    }\n",
        "\n",
        "    print(\"Data sorted\")\n",
        "\n",
        "    try:\n",
        "        os.mkdir(folderDataPath)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    pickle.dump(dict_data, open(folderDataPath + \"data.p\", \"wb\"))\n",
        "    print(\"Data stored\")\n",
        "else:\n",
        "    dict_data = pickle.load(open(folderDataPath + \"data.p\", \"rb\"))\n",
        "\n",
        "\n",
        "\n",
        "modelHandler = ModelHandler(configs)\n",
        " \n",
        "X_all = dict_data[\"x_train\"]\n",
        "ydet_all = dict_data[\"y_train\"][\"detection\"]\n",
        "ytype_all = dict_data[\"y_train\"][\"type\"]\n",
        "yclass_all = dict_data[\"y_train\"][\"classification\"]\n",
        "\n",
        "if configs[\"PERCENTUAL\"][0]!=1:\n",
        "        X_all,ydet_all,ytype_all,yclass_all = reduce_dataset(X_all,ydet_all,ytype_all,yclass_all,configs[\"PERCENTUAL\"][0])\n",
        "\n",
        "print(X_all.shape)\n",
        "print(dict_data[\"x_test\"].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyKE-nTLtYM2",
        "outputId": "a83102ea-5b89-41c0-96b7-7fc0fadb0750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7575, 16640, 1)\n",
            "(841, 16640, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, GlobalAveragePooling1D, Flatten, MaxPool1D, GlobalMaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from kymatio.keras import Scattering1D\n",
        "\n",
        "def buildBaseScattering(input_shape):\n",
        "    '''\n",
        "        Source: https://github.com/kymatio/kymatio/blob/master/examples/1d/classif_keras.py\n",
        "    '''\n",
        "    log_eps = 1e-6\n",
        "    \n",
        "    input = Input(shape=(input_shape,))\n",
        "    x = Scattering1D(10, 10, max_order=1)(input) \n",
        "\n",
        "    unmapped_len = int(0.15 * (x.shape[2] / 1.3))\n",
        "    grid_len = int((x.shape[2] - 2 * unmapped_len) / 5)\n",
        "\n",
        "    print(f\"X: {x.shape[2]}, Unmapped: {unmapped_len}, Grid: {grid_len}\")\n",
        "\n",
        "    left = Lambda(lambda x: x[..., :, : unmapped_len], name='left')(x)\n",
        "    center = Lambda(lambda x: x[..., :, unmapped_len : x.shape[2] - unmapped_len], name='center')(x)\n",
        "    right = Lambda(lambda x: x[..., :, x.shape[2] - unmapped_len :], name='right')(x)\n",
        "\n",
        "    g1 = Lambda(lambda x: x[..., :, :grid_len], name='g1')(center)\n",
        "    g2 = Lambda(lambda x: x[..., :, grid_len:2*grid_len], name='g2')(center)\n",
        "    g3 = Lambda(lambda x: x[..., :, 2*grid_len:3*grid_len], name='g3')(center)\n",
        "    g4 = Lambda(lambda x: x[..., :, 3*grid_len:4*grid_len], name='g4')(center)\n",
        "    g5 = Lambda(lambda x: x[..., :, 4*grid_len:], name='g5')(center)\n",
        "\n",
        "\n",
        "    leftav = tf.keras.backend.max(left, axis=2)\n",
        "    g1av   = tf.keras.backend.max(g1, axis=2)\n",
        "    g2av   = tf.keras.backend.max(g2, axis=2)\n",
        "    g3av   = tf.keras.backend.max(g3, axis=2)\n",
        "    g4av   = tf.keras.backend.max(g4, axis=2)\n",
        "    g5av   = tf.keras.backend.max(g5, axis=2)\n",
        "    rightav = tf.keras.backend.max(right, axis=2)\n",
        "    \n",
        "    \n",
        "    x_type = tf.concat([(g1av-leftav), (g2av-leftav), (g3av-g1av), (g4av-g2av), (g5av-g3av), (rightav-g4av), (rightav-g5av) ], axis=1)\n",
        "    x_class = tf.concat([leftav, g1av, g2av, g3av, g4av, g5av, rightav], axis=1)\n",
        "\n",
        "\n",
        "    x_type = Flatten()(x_type)\n",
        "    x_class = Flatten()(x_class)\n",
        "\n",
        "    model = Model(inputs = input, outputs=[x_type, x_class])\n",
        "\n",
        "    return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "scattering_extract = buildBaseScattering(X_all.shape[1])\n",
        "scattering_extract.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYJUZIMptnFN",
        "outputId": "68934cf1-4b6f-463f-c6f0-955def22929d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: 17, Unmapped: 1, Grid: 3\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 16640)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "scattering1d (Scattering1D)     (None, 86, 17)       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "center (Lambda)                 (None, 86, 15)       0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "g1 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "left (Lambda)                   (None, 86, 1)        0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "g2 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g3 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g4 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g5 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "right (Lambda)                  (None, 86, 1)        0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_1 (TFOpLambd (None, 86)           0           g1[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max (TFOpLambda) (None, 86)           0           left[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_2 (TFOpLambd (None, 86)           0           g2[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_3 (TFOpLambd (None, 86)           0           g3[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_4 (TFOpLambd (None, 86)           0           g4[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_5 (TFOpLambd (None, 86)           0           g5[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_6 (TFOpLambd (None, 86)           0           right[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract (TFOpLambda)   (None, 86)           0           tf.math.reduce_max_1[0][0]       \n",
            "                                                                 tf.math.reduce_max[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_1 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_2[0][0]       \n",
            "                                                                 tf.math.reduce_max[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_2 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_3[0][0]       \n",
            "                                                                 tf.math.reduce_max_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_3 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_4[0][0]       \n",
            "                                                                 tf.math.reduce_max_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_4 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_5[0][0]       \n",
            "                                                                 tf.math.reduce_max_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_5 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_6[0][0]       \n",
            "                                                                 tf.math.reduce_max_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_6 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_6[0][0]       \n",
            "                                                                 tf.math.reduce_max_5[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 602)          0           tf.math.subtract[0][0]           \n",
            "                                                                 tf.math.subtract_1[0][0]         \n",
            "                                                                 tf.math.subtract_2[0][0]         \n",
            "                                                                 tf.math.subtract_3[0][0]         \n",
            "                                                                 tf.math.subtract_4[0][0]         \n",
            "                                                                 tf.math.subtract_5[0][0]         \n",
            "                                                                 tf.math.subtract_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_1 (TFOpLambda)        (None, 602)          0           tf.math.reduce_max[0][0]         \n",
            "                                                                 tf.math.reduce_max_1[0][0]       \n",
            "                                                                 tf.math.reduce_max_2[0][0]       \n",
            "                                                                 tf.math.reduce_max_3[0][0]       \n",
            "                                                                 tf.math.reduce_max_4[0][0]       \n",
            "                                                                 tf.math.reduce_max_5[0][0]       \n",
            "                                                                 tf.math.reduce_max_6[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 602)          0           tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 602)          0           tf.concat_1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
        "\n",
        "\n",
        "def get_flops(model, batch_size=None):\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "\n",
        "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
        "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
        "                                            run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops\n",
        "\n",
        "def get_flops_output(model, batch_size=None):\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    argument = (tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype, name=\"type_input\"),    \n",
        "            tf.TensorSpec([batch_size] + model.inputs[1].shape[1:], model.inputs[0].dtype, name=\"class_input\"))   \n",
        "    real_model = tf.function(model).get_concrete_function(argument)\n",
        "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
        "                                            run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops\n",
        "    "
      ],
      "metadata": {
        "id": "qPeWX7g9tw1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flops_scatt = get_flops(scattering_extract, 32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvJXhKyMvI5L",
        "outputId": "84efd49d-b094-4154-9483-1015b4d18b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"FLOPS of Scattering Network: {flops_scatt / 10**9:.03} G\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIG3Nip1uIZF",
        "outputId": "4096bbc1-ea61-4090-f802-82770525e78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPS of Scattering Network: 0.226 G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argument = (tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype, name=\"type_input\"),    \n",
        "            tf.TensorSpec([batch_size] + model.inputs[1].shape[1:], model.inputs[0].dtype, name=\"class_input\"))\n"
      ],
      "metadata": {
        "id": "hxrHML6e3hTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_model = tf.function(model).get_concrete_function(argument)\n",
        "frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)"
      ],
      "metadata": {
        "id": "Isw7bHB_8n7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_meta = tf.compat.v1.RunMetadata()\n",
        "opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
        "                                            run_meta=run_meta, cmd='op', options=opts)\n"
      ],
      "metadata": {
        "id": "_VlSbPT183Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(flops.total_float_ops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4r97jSf9AgY",
        "outputId": "74bac9a3-e5f4-4ec0-f73e-87a11ec866af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37463840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets include the output network:"
      ],
      "metadata": {
        "id": "Xu3sAidowEfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fold = 1\n",
        "folderPath = configs[\"FOLDER_PATH\"] + str(fold) + \"/\"\n",
        "\n",
        "model_output = ModelHandler.loadModel(folderPath + 'model_without_detection.h5')"
      ],
      "metadata": {
        "id": "SXaAeolHwDfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flops_output = get_flops_output(model_output, 32)\n",
        "\n",
        "print(f\"Scattering FLOPS: {flops_scatt / 10**9:.03} G\")\n",
        "\n",
        "\n",
        "print(f\"Output FLOPS: {flops_output / 10**9:.03} G\")\n",
        "\n",
        "\n",
        "total_flops = flops_scatt + flops_output\n",
        "print(f\"Total FLOPS: {total_flops/ 10**9:.03} G\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAxcOBicxMT0",
        "outputId": "06ea1ba7-1d10-4b1a-e2c7-f2ad9c76b078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scattering FLOPS: 0.226 G\n",
            "Output FLOPS: 0.0375 G\n",
            "Total FLOPS: 0.264 G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlQIVoaDqx0A",
        "outputId": "70893847-f21c-4def-a0f1-a29e53f9dd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 602)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 602)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_0 (Dense)            (None, 300)          180900      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_0 (Dense)  (None, 300)          180900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "type_leaky_0 (LeakyReLU)        (None, 300)          0           type_dense_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_leaky_0 (LeakyRe (None, 300)          0           classification_dense_0[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dropout (Dropout)          (None, 300)          0           type_leaky_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dropout (Dropout (None, 300)          0           classification_leaky_0[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_1 (Dense)            (None, 300)          90300       type_dropout[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_1 (Dense)  (None, 300)          90300       classification_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_leaky_1 (LeakyReLU)        (None, 300)          0           type_dense_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_leaky_1 (LeakyRe (None, 300)          0           classification_dense_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_2 (Dense)            (None, 15)           4515        type_leaky_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_2 (Dense)  (None, 130)          39130       classification_leaky_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type (Reshape)                  (None, 5, 3)         0           type_dense_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification (Reshape)        (None, 5, 26)        0           classification_dense_2[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 586,045\n",
            "Trainable params: 310,330\n",
            "Non-trainable params: 275,715\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}