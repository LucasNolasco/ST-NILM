{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training ST-NILM",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S0dQGDeSzovV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80f2c20-eaa6-4055-99d7-7b05f9f3fe58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlfBsih4yERc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.0\n",
        "!pip install keras==2.4.0\n",
        "!pip install kymatio\n",
        "!pip install tqdm\n",
        "!pip install iterative-stratification\n",
        "!pip install scikit-multilearn"
      ],
      "metadata": {
        "id": "V4QIVfpU0ybn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c260484-3c81-45b4-d5be-b8fa0c679c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 70.0 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68727 sha256=29a272639a88cb9b05660d1e0d1edf0ae342daed92e9543536c93d75b951b967\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.4.0\n",
            "  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.13)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.2.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kymatio\n",
            "  Downloading kymatio-0.2.1-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kymatio) (21.3)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kymatio) (3.0.9)\n",
            "Installing collected packages: configparser, kymatio\n",
            "Successfully installed configparser-5.2.0 kymatio-0.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 8.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append(\"drive/MyDrive/Scattering_Novo/src\")\n",
        "from DataHandler import DataHandler\n",
        "from ModelHandler import ModelHandler\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        " \n",
        "configs = {\n",
        "    \"N_GRIDS\": 5, \n",
        "    \"SIGNAL_BASE_LENGTH\": 12800, \n",
        "    \"N_CLASS\": 26, \n",
        "    \"USE_NO_LOAD\": False, \n",
        "    \"USE_HAND_AUGMENTATION\": True,\n",
        "    \"MARGIN_RATIO\": 0.15, \n",
        "    \"DATASET_PATH\": \"drive/MyDrive/YOLO_NILM/Synthetic_Full_iHall.hdf5\",\n",
        "    \"TRAIN_SIZE\": 0.9,\n",
        "    \"FOLDER_PATH\": \"drive/MyDrive/Scattering_Novo/tmp/DIFDUAL/tests/ANDH100_4/\", \n",
        "    \"FOLDER_DATA_PATH\": \"drive/MyDrive/Scattering_Novo/tmp/Without_Detection_With_HAND/NDH100/\", \n",
        "    \"N_EPOCHS_TRAINING\": 5000,\n",
        "    \"PERCENTUAL\": [1],\n",
        "    \"INITIAL_EPOCH\": 0,\n",
        "    \"TOTAL_MAX_EPOCHS\": 5000,\n",
        "    \"SNRdb\": None # Nível de ruído em db\n",
        "}\n",
        "\n",
        "def freeze(model, task_name='classification'):\n",
        "    for layer in model.layers:\n",
        "        if task_name in layer.name:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "\n",
        "    for layer in model.layers:\n",
        "        print(layer.name, layer.trainable)\n",
        "\n",
        "    return model\n",
        "\n",
        "def calculating_class_weights(y_true):\n",
        "    '''\n",
        "        Source: https://stackoverflow.com/questions/48485870/multi-label-classification-with-class-weights-in-keras\n",
        "    '''\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    number_dim = np.shape(y_true)[1]\n",
        "    weights = np.empty([number_dim, 2])\n",
        "    for i in range(number_dim):\n",
        "        weights[i] = compute_class_weight(class_weight='balanced', classes=[0.,1.], y=y_true[:, i])\n",
        "    return weights\n",
        "\n",
        "\n",
        "def reduce_dataset(X_all,ydet_all,ytype_all,yclass_all,percentual):\n",
        "    import numpy as np\n",
        "    max_index = int(percentual*X_all.shape[0])\n",
        "    np.random.seed(100)\n",
        "    index = np.random.randint(max_index,size=(max_index-1))\n",
        "    X_all = X_all[index]\n",
        "    ydet_all = ydet_all[index]\n",
        "    ytype_all = ytype_all[index]\n",
        "    yclass_all = yclass_all[index]\n",
        "\n",
        "    return X_all,ydet_all,ytype_all,yclass_all\n",
        "\n",
        "ngrids = configs[\"N_GRIDS\"]\n",
        "signalBaseLength = configs[\"SIGNAL_BASE_LENGTH\"]\n",
        "trainSize = configs[\"TRAIN_SIZE\"]\n",
        "folderDataPath = configs[\"FOLDER_DATA_PATH\"]\n",
        " \n",
        "dataHandler = DataHandler(configs)\n",
        "\n",
        "if not os.path.isfile(folderDataPath + \"data.p\"):\n",
        "    print(\"Sorted data not found, creating new file...\")\n",
        "    x, ydet, yclass, ytype, ygroup = dataHandler.loadData(hand_augmentation=configs[\"USE_HAND_AUGMENTATION\"], SNR=configs[\"SNRdb\"])\n",
        "    print(\"Data loaded\")\n",
        "\n",
        "    data_mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    strat_classes = np.max(yclass, axis=1)\n",
        "    train_index, test_index = next(data_mskf.split(x, strat_classes))\n",
        "\n",
        "    y_train = {\n",
        "        \"detection\": ydet[train_index], \n",
        "        \"type\": ytype[train_index], \n",
        "        \"classification\": yclass[train_index], \n",
        "        \"group\": ygroup[train_index]\n",
        "    }\n",
        "    \n",
        "    y_test = {\n",
        "        \"detection\": ydet[test_index], \n",
        "        \"type\": ytype[test_index], \n",
        "        \"classification\": yclass[test_index], \n",
        "        \"group\": ygroup[test_index]\n",
        "    }\n",
        "    \n",
        "    dict_data = {\n",
        "        \"x_train\": x[train_index], \n",
        "        \"x_test\": x[test_index], \n",
        "        \"y_train\": y_train, \n",
        "        \"y_test\": y_test\n",
        "    }\n",
        "\n",
        "    print(\"Data sorted\")\n",
        "\n",
        "    try:\n",
        "        os.mkdir(folderDataPath)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    pickle.dump(dict_data, open(folderDataPath + \"data.p\", \"wb\"))\n",
        "    print(\"Data stored\")\n",
        "else:\n",
        "    dict_data = pickle.load(open(folderDataPath + \"data.p\", \"rb\"))\n",
        "\n",
        "\n",
        "\n",
        "modelHandler = ModelHandler(configs)\n",
        " \n",
        "X_all = dict_data[\"x_train\"]\n",
        "ydet_all = dict_data[\"y_train\"][\"detection\"]\n",
        "ytype_all = dict_data[\"y_train\"][\"type\"]\n",
        "yclass_all = dict_data[\"y_train\"][\"classification\"]\n",
        "\n",
        "if configs[\"PERCENTUAL\"][0]!=1:\n",
        "        X_all,ydet_all,ytype_all,yclass_all = reduce_dataset(X_all,ydet_all,ytype_all,yclass_all,configs[\"PERCENTUAL\"][0])\n",
        "\n",
        "print(X_all.shape)\n",
        "print(dict_data[\"x_test\"].shape)\n"
      ],
      "metadata": {
        "id": "8FfVMPp26zwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d1bb4b-5a9e-45e4-f69d-6ae28e1e7877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18723, 16640, 1)\n",
            "(2089, 16640, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configs[\"PERCENTUAL\"][0]"
      ],
      "metadata": {
        "id": "NMwhhPfNdUc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1386e1-a5f0-481e-e97c-86fe4dd9513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, GlobalAveragePooling1D, Flatten, MaxPool1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from kymatio.keras import Scattering1D\n",
        "\n",
        "def buildBaseScattering(input_shape):\n",
        "    '''\n",
        "        Source: https://github.com/kymatio/kymatio/blob/master/examples/1d/classif_keras.py\n",
        "    '''\n",
        "    log_eps = 1e-6\n",
        "    \n",
        "    input = Input(shape=(input_shape,))\n",
        "    x = Scattering1D(10, 10, max_order=1)(input) # Changed J from 8 to 10 -> Results in a flatten with 544 parameters (the original with convolutions has 520)\n",
        "    \n",
        "\n",
        "    unmapped_len = int(0.15 * (x.shape[2] / 1.3))\n",
        "    grid_len = int((x.shape[2] - 2 * unmapped_len) / 5)\n",
        "\n",
        "    print(f\"X: {x.shape[2]}, Unmapped: {unmapped_len}, Grid: {grid_len}\")\n",
        "\n",
        "    left = Lambda(lambda x: x[..., :, : unmapped_len], name='left')(x)\n",
        "    center = Lambda(lambda x: x[..., :, unmapped_len : x.shape[2] - unmapped_len], name='center')(x)\n",
        "    right = Lambda(lambda x: x[..., :, x.shape[2] - unmapped_len :], name='right')(x)\n",
        "\n",
        "    g1 = Lambda(lambda x: x[..., :, :grid_len], name='g1')(center)\n",
        "    g2 = Lambda(lambda x: x[..., :, grid_len:2*grid_len], name='g2')(center)\n",
        "    g3 = Lambda(lambda x: x[..., :, 2*grid_len:3*grid_len], name='g3')(center)\n",
        "    g4 = Lambda(lambda x: x[..., :, 3*grid_len:4*grid_len], name='g4')(center)\n",
        "    g5 = Lambda(lambda x: x[..., :, 4*grid_len:], name='g5')(center)\n",
        "\n",
        "\n",
        "    leftav = tf.keras.backend.max(left, axis=2)\n",
        "    g1av   = tf.keras.backend.max(g1, axis=2)\n",
        "    g2av   = tf.keras.backend.max(g2, axis=2)\n",
        "    g3av   = tf.keras.backend.max(g3, axis=2)\n",
        "    g4av   = tf.keras.backend.max(g4, axis=2)\n",
        "    g5av   = tf.keras.backend.max(g5, axis=2)\n",
        "    rightav = tf.keras.backend.max(right, axis=2)\n",
        "    \n",
        "    \n",
        "\n",
        "    x_type = tf.concat([(g1av-leftav), (g2av-leftav), (g3av-g1av), (g4av-g2av), (g5av-g3av), (rightav-g4av), (rightav-g5av) ], axis=1)\n",
        "\n",
        "\n",
        "    x_class = tf.concat([leftav, g1av, g2av, g3av, g4av, g5av, rightav], axis=1)\n",
        "  \n",
        "    x_type = Flatten()(x_type)\n",
        "    x_class = Flatten()(x_class)\n",
        "\n",
        "\n",
        "    model = Model(inputs = input, outputs=[x_type, x_class])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "scattering_extract = buildBaseScattering(X_all.shape[1])\n",
        "scattering_extract.summary()"
      ],
      "metadata": {
        "id": "OO_3NWFj3pw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17ab13f-4a1d-4f6d-e292-81a022cfe1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: 17, Unmapped: 1, Grid: 3\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 16640)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "scattering1d (Scattering1D)     (None, 86, 17)       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "center (Lambda)                 (None, 86, 15)       0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "g1 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "left (Lambda)                   (None, 86, 1)        0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "g2 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g3 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g4 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g5 (Lambda)                     (None, 86, 3)        0           center[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "right (Lambda)                  (None, 86, 1)        0           scattering1d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_1 (TFOpLambd (None, 86)           0           g1[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max (TFOpLambda) (None, 86)           0           left[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_2 (TFOpLambd (None, 86)           0           g2[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_3 (TFOpLambd (None, 86)           0           g3[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_4 (TFOpLambd (None, 86)           0           g4[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_5 (TFOpLambd (None, 86)           0           g5[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_6 (TFOpLambd (None, 86)           0           right[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract (TFOpLambda)   (None, 86)           0           tf.math.reduce_max_1[0][0]       \n",
            "                                                                 tf.math.reduce_max[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_1 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_2[0][0]       \n",
            "                                                                 tf.math.reduce_max[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_2 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_3[0][0]       \n",
            "                                                                 tf.math.reduce_max_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_3 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_4[0][0]       \n",
            "                                                                 tf.math.reduce_max_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_4 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_5[0][0]       \n",
            "                                                                 tf.math.reduce_max_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_5 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_6[0][0]       \n",
            "                                                                 tf.math.reduce_max_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_6 (TFOpLambda) (None, 86)           0           tf.math.reduce_max_6[0][0]       \n",
            "                                                                 tf.math.reduce_max_5[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 602)          0           tf.math.subtract[0][0]           \n",
            "                                                                 tf.math.subtract_1[0][0]         \n",
            "                                                                 tf.math.subtract_2[0][0]         \n",
            "                                                                 tf.math.subtract_3[0][0]         \n",
            "                                                                 tf.math.subtract_4[0][0]         \n",
            "                                                                 tf.math.subtract_5[0][0]         \n",
            "                                                                 tf.math.subtract_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_1 (TFOpLambda)        (None, 602)          0           tf.math.reduce_max[0][0]         \n",
            "                                                                 tf.math.reduce_max_1[0][0]       \n",
            "                                                                 tf.math.reduce_max_2[0][0]       \n",
            "                                                                 tf.math.reduce_max_3[0][0]       \n",
            "                                                                 tf.math.reduce_max_4[0][0]       \n",
            "                                                                 tf.math.reduce_max_5[0][0]       \n",
            "                                                                 tf.math.reduce_max_6[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 602)          0           tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 602)          0           tf.concat_1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scattering_extract.save(configs[\"FOLDER_PATH\"] + 'scattering_model.h5')"
      ],
      "metadata": {
        "id": "W4rEcj1PdiMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento"
      ],
      "metadata": {
        "id": "t3nQSewBZAkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fold = 0\n",
        "mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "strat_classes = np.max(yclass_all, axis=1)\n",
        "print(strat_classes.shape)\n",
        "\n",
        "for train_index, validation_index in mskf.split(X_all, strat_classes):\n",
        "    fold += 1\n",
        "\n",
        "    if fold != 6:\n",
        "        continue\n",
        "\n",
        "    print(f\"---------- FOLD {fold} -------------\")\n",
        "\n",
        "    scaler = MaxAbsScaler()\n",
        "    scaler.fit(np.squeeze(X_all[train_index], axis=2))\n",
        "    x_train = np.expand_dims(scaler.transform(np.squeeze(X_all[train_index], axis=2)), axis=2)\n",
        "    x_validation = np.expand_dims(scaler.transform(np.squeeze(X_all[validation_index], axis=2)), axis=2)\n",
        "    \n",
        "    \n",
        "    x_train_type, x_train_class = scattering_extract.predict(x_train)\n",
        "    x_validation_type, x_validation_class = scattering_extract.predict(x_validation)\n",
        "\n",
        "    # Normalizing\n",
        "\n",
        "    transformer = MaxAbsScaler().fit(x_train_type)\n",
        "    x_train_type = transformer.transform(x_train_type)\n",
        "    \n",
        "    transformer = MaxAbsScaler().fit(x_train_class)\n",
        "    x_train_class = transformer.transform(x_train_class)\n",
        "\n",
        "    transformer = MaxAbsScaler().fit(x_validation_type)\n",
        "    x_validation_type = transformer.transform(x_validation_type)\n",
        "\n",
        "    transformer = MaxAbsScaler().fit(x_validation_class)\n",
        "    x_validation_class = transformer.transform(x_validation_class)\n",
        "\n",
        "    print(\"Each grid has size \" + str(x_train[1].shape))\n",
        "\n",
        "    y_train, y_validation = {}, {}\n",
        "    y_train[\"detection\"] = ydet_all[train_index]\n",
        "    y_validation[\"detection\"] = ydet_all[validation_index]\n",
        "    y_train[\"type\"] = ytype_all[train_index]\n",
        "    y_validation[\"type\"] = ytype_all[validation_index]\n",
        "    y_train[\"classification\"] = yclass_all[train_index]\n",
        "    y_validation[\"classification\"] = yclass_all[validation_index]\n",
        "\n",
        "    yclass_weights = calculating_class_weights(np.max(y_train[\"classification\"], axis=1))\n",
        "\n",
        "    print(yclass_weights)\n",
        "    \n",
        "    folderPath = configs[\"FOLDER_PATH\"] + str(fold) + \"/\"\n",
        "    try:\n",
        "        os.mkdir(folderPath)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    np.save(folderPath + \"train_index.npy\", train_index)\n",
        "    np.save(folderPath + \"validation_index.npy\", validation_index)\n",
        "    \n",
        "\n",
        "    tensorboard_callback = TensorBoard(log_dir='./' + configs[\"FOLDER_PATH\"] + '/logs')\n",
        "\n",
        "\n",
        "    if configs[\"INITIAL_EPOCH\"] > 0:\n",
        "        model = ModelHandler.loadModel(folderPath + 'model_{0}.h5'.format(configs[\"INITIAL_EPOCH\"]))\n",
        "    else:\n",
        "        model = modelHandler.buildScatteringOutput3(input_shape=x_train_type.shape[1]) \n",
        " \n",
        "    model.summary()\n",
        " \n",
        "    fileEpoch = configs[\"INITIAL_EPOCH\"]\n",
        "    while fileEpoch < configs[\"TOTAL_MAX_EPOCHS\"]:\n",
        "        fileEpoch += configs[\"N_EPOCHS_TRAINING\"]      \n",
        "\n",
        "        if not os.path.isfile(folderPath + 'model_without_detection.h5'):\n",
        "            for subtask in ['type', 'classification']:\n",
        "                print(f\"FOLD {fold}: Training {subtask}\")\n",
        "                \n",
        "                freeze(model, task_name=subtask)\n",
        "                model.compile(optimizer = Adam(), \\\n",
        "                            \n",
        "                              loss = [\"categorical_crossentropy\", \"binary_crossentropy\"], \\\n",
        "                              metrics=[['categorical_accuracy'], ['binary_accuracy']])\n",
        "                \n",
        "                early_stopping_callback = EarlyStopping(monitor=f\"val_{subtask}_loss\", patience=50, verbose=True, restore_best_weights=True)\n",
        "                \n",
        "                hist_opt = model.fit(x=[x_train_type, x_train_class], y=[y_train[\"type\"], y_train[\"classification\"]], \\\n",
        "                                    validation_data=([x_validation_type, x_validation_class], [y_validation[\"type\"], y_validation[\"classification\"]]), \\\n",
        "                                    epochs=configs[\"N_EPOCHS_TRAINING\"], verbose=2, callbacks=[early_stopping_callback, tensorboard_callback], batch_size=32)\n",
        "                \n",
        "                   \n",
        "            model.save(folderPath + 'model_without_detection.h5')\n",
        "  \n",
        "    del model, y_validation, y_train, x_validation, x_train"
      ],
      "metadata": {
        "id": "725br4I6ZBDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6ec98c-a847-4d10-d0c0-e1545a682574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18723, 26)\n",
            "---------- FOLD 6 -------------\n",
            "Each grid has size (16640, 1)\n",
            "[[ 0.5498953   5.5104918 ]\n",
            " [ 0.55083246  5.41811734]\n",
            " [ 0.50302287 83.2029703 ]\n",
            " [ 0.5604949   4.63257993]\n",
            " [ 0.57585829  3.79561879]\n",
            " [ 0.50389758 64.64230769]\n",
            " [ 0.51867053 13.89008264]\n",
            " [ 0.61245536  2.72310434]\n",
            " [ 0.54799478  5.70889946]\n",
            " [ 0.50544328 46.4281768 ]\n",
            " [ 0.51159747 22.05643045]\n",
            " [ 0.55652318  4.92296426]\n",
            " [ 0.66992188  1.97126437]\n",
            " [ 0.57573993  3.80076888]\n",
            " [ 0.50696791 36.37878788]\n",
            " [ 0.57696533  3.74821588]\n",
            " [ 0.56965157  4.0892944 ]\n",
            " [ 0.51739318 14.87345133]\n",
            " [ 0.52666708  9.87485311]\n",
            " [ 0.51768003 14.6402439 ]\n",
            " [ 0.52746046  9.604     ]\n",
            " [ 0.53072502  8.63669065]\n",
            " [ 0.53477791  7.6884721 ]\n",
            " [ 0.52397431 10.92782835]\n",
            " [ 0.53693055  7.26946367]\n",
            " [ 0.53335237  7.99571836]]\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 602)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 602)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_0 (Dense)            (None, 300)          180900      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_0 (Dense)  (None, 300)          180900      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "type_leaky_0 (LeakyReLU)        (None, 300)          0           type_dense_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_leaky_0 (LeakyRe (None, 300)          0           classification_dense_0[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dropout (Dropout)          (None, 300)          0           type_leaky_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dropout (Dropout (None, 300)          0           classification_leaky_0[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_1 (Dense)            (None, 300)          90300       type_dropout[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_1 (Dense)  (None, 300)          90300       classification_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_leaky_1 (LeakyReLU)        (None, 300)          0           type_dense_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_leaky_1 (LeakyRe (None, 300)          0           classification_dense_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type_dense_2 (Dense)            (None, 15)           4515        type_leaky_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification_dense_2 (Dense)  (None, 130)          39130       classification_leaky_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "type (Reshape)                  (None, 5, 3)         0           type_dense_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "classification (Reshape)        (None, 5, 26)        0           classification_dense_2[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 586,045\n",
            "Trainable params: 586,045\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "FOLD 6: Training type\n",
            "input_5 False\n",
            "input_4 False\n",
            "type_dense_0 True\n",
            "classification_dense_0 False\n",
            "type_leaky_0 True\n",
            "classification_leaky_0 False\n",
            "type_dropout True\n",
            "classification_dropout False\n",
            "type_dense_1 True\n",
            "classification_dense_1 False\n",
            "type_leaky_1 True\n",
            "classification_leaky_1 False\n",
            "type_dense_2 True\n",
            "classification_dense_2 False\n",
            "type True\n",
            "classification False\n",
            "Epoch 1/5000\n",
            "526/526 - 4s - loss: 0.9304 - type_loss: 0.2327 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9195 - classification_binary_accuracy: 0.4925 - val_loss: 0.8562 - val_type_loss: 0.1584 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9300 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 2/5000\n",
            "526/526 - 2s - loss: 0.8558 - type_loss: 0.1582 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9292 - classification_binary_accuracy: 0.4926 - val_loss: 0.8358 - val_type_loss: 0.1381 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9377 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 3/5000\n",
            "526/526 - 2s - loss: 0.8399 - type_loss: 0.1423 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9393 - classification_binary_accuracy: 0.4928 - val_loss: 0.8328 - val_type_loss: 0.1350 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9522 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 4/5000\n",
            "526/526 - 2s - loss: 0.8273 - type_loss: 0.1296 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9498 - classification_binary_accuracy: 0.4925 - val_loss: 0.8297 - val_type_loss: 0.1319 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9554 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 5/5000\n",
            "526/526 - 2s - loss: 0.8170 - type_loss: 0.1193 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9565 - classification_binary_accuracy: 0.4930 - val_loss: 0.8187 - val_type_loss: 0.1210 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9637 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 6/5000\n",
            "526/526 - 3s - loss: 0.8078 - type_loss: 0.1101 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9614 - classification_binary_accuracy: 0.4929 - val_loss: 0.8198 - val_type_loss: 0.1220 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9643 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 7/5000\n",
            "526/526 - 3s - loss: 0.8028 - type_loss: 0.1051 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9671 - classification_binary_accuracy: 0.4927 - val_loss: 0.8057 - val_type_loss: 0.1079 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9691 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 8/5000\n",
            "526/526 - 2s - loss: 0.7926 - type_loss: 0.0950 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9697 - classification_binary_accuracy: 0.4930 - val_loss: 0.7979 - val_type_loss: 0.1001 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9713 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 9/5000\n",
            "526/526 - 2s - loss: 0.7849 - type_loss: 0.0872 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9716 - classification_binary_accuracy: 0.4927 - val_loss: 0.8057 - val_type_loss: 0.1080 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9690 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 10/5000\n",
            "526/526 - 2s - loss: 0.7812 - type_loss: 0.0836 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9731 - classification_binary_accuracy: 0.4927 - val_loss: 0.7950 - val_type_loss: 0.0973 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9744 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 11/5000\n",
            "526/526 - 2s - loss: 0.7754 - type_loss: 0.0777 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9749 - classification_binary_accuracy: 0.4928 - val_loss: 0.7895 - val_type_loss: 0.0918 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9727 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 12/5000\n",
            "526/526 - 2s - loss: 0.7708 - type_loss: 0.0732 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9761 - classification_binary_accuracy: 0.4922 - val_loss: 0.7823 - val_type_loss: 0.0846 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9754 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 13/5000\n",
            "526/526 - 2s - loss: 0.7721 - type_loss: 0.0744 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9757 - classification_binary_accuracy: 0.4926 - val_loss: 0.7977 - val_type_loss: 0.1000 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9693 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 14/5000\n",
            "526/526 - 2s - loss: 0.7681 - type_loss: 0.0704 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9760 - classification_binary_accuracy: 0.4928 - val_loss: 0.8249 - val_type_loss: 0.1271 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9479 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 15/5000\n",
            "526/526 - 2s - loss: 0.7640 - type_loss: 0.0664 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9784 - classification_binary_accuracy: 0.4926 - val_loss: 0.7967 - val_type_loss: 0.0990 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9694 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 16/5000\n",
            "526/526 - 2s - loss: 0.7622 - type_loss: 0.0645 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9790 - classification_binary_accuracy: 0.4928 - val_loss: 0.8066 - val_type_loss: 0.1088 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9601 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 17/5000\n",
            "526/526 - 2s - loss: 0.7662 - type_loss: 0.0686 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9779 - classification_binary_accuracy: 0.4925 - val_loss: 0.8235 - val_type_loss: 0.1258 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9558 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 18/5000\n",
            "526/526 - 2s - loss: 0.7619 - type_loss: 0.0643 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9792 - classification_binary_accuracy: 0.4924 - val_loss: 0.8073 - val_type_loss: 0.1096 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9688 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 19/5000\n",
            "526/526 - 2s - loss: 0.7569 - type_loss: 0.0593 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9800 - classification_binary_accuracy: 0.4929 - val_loss: 0.7925 - val_type_loss: 0.0947 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9735 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 20/5000\n",
            "526/526 - 2s - loss: 0.7566 - type_loss: 0.0590 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9809 - classification_binary_accuracy: 0.4929 - val_loss: 0.8016 - val_type_loss: 0.1039 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9735 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 21/5000\n",
            "526/526 - 2s - loss: 0.7618 - type_loss: 0.0642 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9782 - classification_binary_accuracy: 0.4928 - val_loss: 0.7914 - val_type_loss: 0.0937 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9733 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 22/5000\n",
            "526/526 - 2s - loss: 0.7527 - type_loss: 0.0550 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9819 - classification_binary_accuracy: 0.4927 - val_loss: 0.7822 - val_type_loss: 0.0844 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9741 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 23/5000\n",
            "526/526 - 2s - loss: 0.7552 - type_loss: 0.0576 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9811 - classification_binary_accuracy: 0.4924 - val_loss: 0.8304 - val_type_loss: 0.1326 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9596 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 24/5000\n",
            "526/526 - 2s - loss: 0.7518 - type_loss: 0.0542 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9820 - classification_binary_accuracy: 0.4927 - val_loss: 0.8225 - val_type_loss: 0.1248 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9604 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 25/5000\n",
            "526/526 - 2s - loss: 0.7503 - type_loss: 0.0527 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9837 - classification_binary_accuracy: 0.4926 - val_loss: 0.7946 - val_type_loss: 0.0968 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9751 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 26/5000\n",
            "526/526 - 2s - loss: 0.7496 - type_loss: 0.0520 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9829 - classification_binary_accuracy: 0.4927 - val_loss: 0.7997 - val_type_loss: 0.1019 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9754 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 27/5000\n",
            "526/526 - 2s - loss: 0.7501 - type_loss: 0.0525 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9832 - classification_binary_accuracy: 0.4928 - val_loss: 0.7867 - val_type_loss: 0.0890 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9748 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 28/5000\n",
            "526/526 - 2s - loss: 0.7471 - type_loss: 0.0494 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9838 - classification_binary_accuracy: 0.4927 - val_loss: 0.8198 - val_type_loss: 0.1220 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9645 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 29/5000\n",
            "526/526 - 2s - loss: 0.7472 - type_loss: 0.0496 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9838 - classification_binary_accuracy: 0.4925 - val_loss: 0.7861 - val_type_loss: 0.0883 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9757 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 30/5000\n",
            "526/526 - 2s - loss: 0.7437 - type_loss: 0.0461 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9849 - classification_binary_accuracy: 0.4926 - val_loss: 0.7970 - val_type_loss: 0.0992 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9704 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 31/5000\n",
            "526/526 - 2s - loss: 0.7460 - type_loss: 0.0484 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9837 - classification_binary_accuracy: 0.4922 - val_loss: 0.8497 - val_type_loss: 0.1519 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9542 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 32/5000\n",
            "526/526 - 2s - loss: 0.7467 - type_loss: 0.0490 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9844 - classification_binary_accuracy: 0.4929 - val_loss: 0.8054 - val_type_loss: 0.1076 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9759 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 33/5000\n",
            "526/526 - 2s - loss: 0.7440 - type_loss: 0.0464 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9850 - classification_binary_accuracy: 0.4925 - val_loss: 0.7797 - val_type_loss: 0.0820 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9756 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 34/5000\n",
            "526/526 - 2s - loss: 0.7426 - type_loss: 0.0449 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9854 - classification_binary_accuracy: 0.4924 - val_loss: 0.7948 - val_type_loss: 0.0971 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9731 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 35/5000\n",
            "526/526 - 2s - loss: 0.7436 - type_loss: 0.0460 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9844 - classification_binary_accuracy: 0.4927 - val_loss: 0.7995 - val_type_loss: 0.1017 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9737 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 36/5000\n",
            "526/526 - 2s - loss: 0.7402 - type_loss: 0.0425 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9858 - classification_binary_accuracy: 0.4922 - val_loss: 0.7984 - val_type_loss: 0.1006 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9752 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 37/5000\n",
            "526/526 - 2s - loss: 0.7397 - type_loss: 0.0421 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.4928 - val_loss: 0.8071 - val_type_loss: 0.1093 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9743 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 38/5000\n",
            "526/526 - 2s - loss: 0.7418 - type_loss: 0.0442 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9856 - classification_binary_accuracy: 0.4925 - val_loss: 0.7742 - val_type_loss: 0.0765 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 39/5000\n",
            "526/526 - 2s - loss: 0.7423 - type_loss: 0.0446 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9856 - classification_binary_accuracy: 0.4925 - val_loss: 0.8143 - val_type_loss: 0.1166 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9712 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 40/5000\n",
            "526/526 - 2s - loss: 0.7370 - type_loss: 0.0394 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.4929 - val_loss: 0.7959 - val_type_loss: 0.0981 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9751 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 41/5000\n",
            "526/526 - 2s - loss: 0.7387 - type_loss: 0.0410 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.4926 - val_loss: 0.8110 - val_type_loss: 0.1132 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9741 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 42/5000\n",
            "526/526 - 2s - loss: 0.7417 - type_loss: 0.0441 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.4930 - val_loss: 0.7936 - val_type_loss: 0.0958 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9756 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 43/5000\n",
            "526/526 - 2s - loss: 0.7364 - type_loss: 0.0387 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.4925 - val_loss: 0.7805 - val_type_loss: 0.0827 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9794 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 44/5000\n",
            "526/526 - 2s - loss: 0.7348 - type_loss: 0.0372 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9875 - classification_binary_accuracy: 0.4928 - val_loss: 0.7937 - val_type_loss: 0.0960 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9768 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 45/5000\n",
            "526/526 - 2s - loss: 0.7351 - type_loss: 0.0375 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9878 - classification_binary_accuracy: 0.4929 - val_loss: 0.7930 - val_type_loss: 0.0952 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9788 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 46/5000\n",
            "526/526 - 2s - loss: 0.7363 - type_loss: 0.0387 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9872 - classification_binary_accuracy: 0.4929 - val_loss: 0.8252 - val_type_loss: 0.1274 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9734 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 47/5000\n",
            "526/526 - 2s - loss: 0.7368 - type_loss: 0.0392 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.4926 - val_loss: 0.7948 - val_type_loss: 0.0971 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9773 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 48/5000\n",
            "526/526 - 2s - loss: 0.7353 - type_loss: 0.0377 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9872 - classification_binary_accuracy: 0.4928 - val_loss: 0.7961 - val_type_loss: 0.0984 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 49/5000\n",
            "526/526 - 2s - loss: 0.7344 - type_loss: 0.0368 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9878 - classification_binary_accuracy: 0.4927 - val_loss: 0.8117 - val_type_loss: 0.1139 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9745 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 50/5000\n",
            "526/526 - 2s - loss: 0.7359 - type_loss: 0.0382 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9879 - classification_binary_accuracy: 0.4930 - val_loss: 0.8412 - val_type_loss: 0.1435 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9618 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 51/5000\n",
            "526/526 - 2s - loss: 0.7370 - type_loss: 0.0393 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.4925 - val_loss: 0.8667 - val_type_loss: 0.1690 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9548 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 52/5000\n",
            "526/526 - 2s - loss: 0.7349 - type_loss: 0.0373 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9883 - classification_binary_accuracy: 0.4928 - val_loss: 0.8062 - val_type_loss: 0.1085 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9780 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 53/5000\n",
            "526/526 - 2s - loss: 0.7342 - type_loss: 0.0366 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9880 - classification_binary_accuracy: 0.4927 - val_loss: 0.8282 - val_type_loss: 0.1304 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9677 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 54/5000\n",
            "526/526 - 2s - loss: 0.7340 - type_loss: 0.0363 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9878 - classification_binary_accuracy: 0.4925 - val_loss: 0.8050 - val_type_loss: 0.1072 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9740 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 55/5000\n",
            "526/526 - 2s - loss: 0.7351 - type_loss: 0.0375 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9878 - classification_binary_accuracy: 0.4925 - val_loss: 0.7984 - val_type_loss: 0.1006 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9740 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 56/5000\n",
            "526/526 - 2s - loss: 0.7304 - type_loss: 0.0327 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9890 - classification_binary_accuracy: 0.4928 - val_loss: 0.8019 - val_type_loss: 0.1042 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9776 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 57/5000\n",
            "526/526 - 2s - loss: 0.7333 - type_loss: 0.0357 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9886 - classification_binary_accuracy: 0.4927 - val_loss: 0.8400 - val_type_loss: 0.1422 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9580 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 58/5000\n",
            "526/526 - 2s - loss: 0.7323 - type_loss: 0.0346 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9884 - classification_binary_accuracy: 0.4926 - val_loss: 0.8011 - val_type_loss: 0.1033 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9756 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 59/5000\n",
            "526/526 - 2s - loss: 0.7306 - type_loss: 0.0329 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9889 - classification_binary_accuracy: 0.4927 - val_loss: 0.8255 - val_type_loss: 0.1278 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9694 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 60/5000\n",
            "526/526 - 2s - loss: 0.7318 - type_loss: 0.0341 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9885 - classification_binary_accuracy: 0.4927 - val_loss: 0.8128 - val_type_loss: 0.1151 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9741 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 61/5000\n",
            "526/526 - 2s - loss: 0.7295 - type_loss: 0.0319 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9892 - classification_binary_accuracy: 0.4924 - val_loss: 0.8200 - val_type_loss: 0.1223 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9756 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 62/5000\n",
            "526/526 - 2s - loss: 0.7335 - type_loss: 0.0358 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9883 - classification_binary_accuracy: 0.4927 - val_loss: 0.8103 - val_type_loss: 0.1126 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9751 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 63/5000\n",
            "526/526 - 2s - loss: 0.7287 - type_loss: 0.0311 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9891 - classification_binary_accuracy: 0.4930 - val_loss: 0.8528 - val_type_loss: 0.1550 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9579 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 64/5000\n",
            "526/526 - 2s - loss: 0.7349 - type_loss: 0.0373 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9885 - classification_binary_accuracy: 0.4926 - val_loss: 0.8277 - val_type_loss: 0.1299 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9677 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 65/5000\n",
            "526/526 - 2s - loss: 0.7315 - type_loss: 0.0339 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9883 - classification_binary_accuracy: 0.4927 - val_loss: 0.8129 - val_type_loss: 0.1152 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9728 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 66/5000\n",
            "526/526 - 2s - loss: 0.7288 - type_loss: 0.0312 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9897 - classification_binary_accuracy: 0.4925 - val_loss: 0.8084 - val_type_loss: 0.1107 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9762 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 67/5000\n",
            "526/526 - 2s - loss: 0.7275 - type_loss: 0.0299 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9900 - classification_binary_accuracy: 0.4925 - val_loss: 0.8084 - val_type_loss: 0.1106 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9766 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 68/5000\n",
            "526/526 - 2s - loss: 0.7304 - type_loss: 0.0327 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9893 - classification_binary_accuracy: 0.4925 - val_loss: 0.8273 - val_type_loss: 0.1295 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9707 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 69/5000\n",
            "526/526 - 2s - loss: 0.7307 - type_loss: 0.0330 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9889 - classification_binary_accuracy: 0.4925 - val_loss: 0.8250 - val_type_loss: 0.1272 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9692 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 70/5000\n",
            "526/526 - 2s - loss: 0.7289 - type_loss: 0.0313 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9903 - classification_binary_accuracy: 0.4926 - val_loss: 0.8261 - val_type_loss: 0.1284 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9754 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 71/5000\n",
            "526/526 - 2s - loss: 0.7288 - type_loss: 0.0311 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9893 - classification_binary_accuracy: 0.4925 - val_loss: 0.8025 - val_type_loss: 0.1047 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9779 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 72/5000\n",
            "526/526 - 2s - loss: 0.7287 - type_loss: 0.0310 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9898 - classification_binary_accuracy: 0.4923 - val_loss: 0.7992 - val_type_loss: 0.1015 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9769 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 73/5000\n",
            "526/526 - 2s - loss: 0.7304 - type_loss: 0.0327 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9891 - classification_binary_accuracy: 0.4924 - val_loss: 0.8186 - val_type_loss: 0.1208 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9763 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 74/5000\n",
            "526/526 - 2s - loss: 0.7264 - type_loss: 0.0287 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9905 - classification_binary_accuracy: 0.4921 - val_loss: 0.8392 - val_type_loss: 0.1415 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9693 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 75/5000\n",
            "526/526 - 2s - loss: 0.7303 - type_loss: 0.0327 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9891 - classification_binary_accuracy: 0.4929 - val_loss: 0.8006 - val_type_loss: 0.1028 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9776 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 76/5000\n",
            "526/526 - 2s - loss: 0.7262 - type_loss: 0.0286 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9899 - classification_binary_accuracy: 0.4926 - val_loss: 0.8204 - val_type_loss: 0.1227 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9710 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 77/5000\n",
            "526/526 - 2s - loss: 0.7294 - type_loss: 0.0317 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9896 - classification_binary_accuracy: 0.4928 - val_loss: 0.8257 - val_type_loss: 0.1280 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9733 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 78/5000\n",
            "526/526 - 2s - loss: 0.7244 - type_loss: 0.0268 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9900 - classification_binary_accuracy: 0.4926 - val_loss: 0.8045 - val_type_loss: 0.1068 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9789 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 79/5000\n",
            "526/526 - 2s - loss: 0.7279 - type_loss: 0.0303 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9903 - classification_binary_accuracy: 0.4929 - val_loss: 0.8110 - val_type_loss: 0.1133 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9781 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 80/5000\n",
            "526/526 - 2s - loss: 0.7265 - type_loss: 0.0289 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9903 - classification_binary_accuracy: 0.4929 - val_loss: 0.8172 - val_type_loss: 0.1195 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9761 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 81/5000\n",
            "526/526 - 2s - loss: 0.7297 - type_loss: 0.0320 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9899 - classification_binary_accuracy: 0.4926 - val_loss: 0.8106 - val_type_loss: 0.1128 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9731 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 82/5000\n",
            "526/526 - 2s - loss: 0.7262 - type_loss: 0.0285 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9904 - classification_binary_accuracy: 0.4927 - val_loss: 0.7998 - val_type_loss: 0.1021 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9779 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 83/5000\n",
            "526/526 - 2s - loss: 0.7238 - type_loss: 0.0261 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9909 - classification_binary_accuracy: 0.4924 - val_loss: 0.8281 - val_type_loss: 0.1304 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9737 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 84/5000\n",
            "526/526 - 2s - loss: 0.7272 - type_loss: 0.0296 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9909 - classification_binary_accuracy: 0.4931 - val_loss: 0.8219 - val_type_loss: 0.1241 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9713 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 85/5000\n",
            "526/526 - 2s - loss: 0.7274 - type_loss: 0.0298 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9906 - classification_binary_accuracy: 0.4933 - val_loss: 0.8388 - val_type_loss: 0.1410 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9720 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 86/5000\n",
            "526/526 - 2s - loss: 0.7283 - type_loss: 0.0306 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9900 - classification_binary_accuracy: 0.4928 - val_loss: 0.8231 - val_type_loss: 0.1254 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9735 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 87/5000\n",
            "526/526 - 2s - loss: 0.7248 - type_loss: 0.0272 - classification_loss: 0.6977 - type_categorical_accuracy: 0.9905 - classification_binary_accuracy: 0.4926 - val_loss: 0.8239 - val_type_loss: 0.1262 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9740 - val_classification_binary_accuracy: 0.4869\n",
            "Epoch 88/5000\n",
            "526/526 - 2s - loss: 0.7258 - type_loss: 0.0282 - classification_loss: 0.6976 - type_categorical_accuracy: 0.9906 - classification_binary_accuracy: 0.4926 - val_loss: 0.8018 - val_type_loss: 0.1041 - val_classification_loss: 0.6977 - val_type_categorical_accuracy: 0.9779 - val_classification_binary_accuracy: 0.4869\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00088: early stopping\n",
            "FOLD 6: Training classification\n",
            "input_5 False\n",
            "input_4 False\n",
            "type_dense_0 False\n",
            "classification_dense_0 True\n",
            "type_leaky_0 False\n",
            "classification_leaky_0 True\n",
            "type_dropout False\n",
            "classification_dropout True\n",
            "type_dense_1 False\n",
            "classification_dense_1 True\n",
            "type_leaky_1 False\n",
            "classification_leaky_1 True\n",
            "type_dense_2 False\n",
            "classification_dense_2 True\n",
            "type False\n",
            "classification True\n",
            "Epoch 1/5000\n",
            "526/526 - 3s - loss: 0.2085 - type_loss: 0.0404 - classification_loss: 0.1681 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9446 - val_loss: 0.1733 - val_type_loss: 0.0765 - val_classification_loss: 0.0968 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9649\n",
            "Epoch 2/5000\n",
            "526/526 - 2s - loss: 0.1273 - type_loss: 0.0413 - classification_loss: 0.0860 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9678 - val_loss: 0.1495 - val_type_loss: 0.0765 - val_classification_loss: 0.0731 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9716\n",
            "Epoch 3/5000\n",
            "526/526 - 2s - loss: 0.1082 - type_loss: 0.0404 - classification_loss: 0.0678 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9741 - val_loss: 0.1374 - val_type_loss: 0.0765 - val_classification_loss: 0.0609 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9774\n",
            "Epoch 4/5000\n",
            "526/526 - 2s - loss: 0.0969 - type_loss: 0.0407 - classification_loss: 0.0562 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.9787 - val_loss: 0.1291 - val_type_loss: 0.0765 - val_classification_loss: 0.0526 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9805\n",
            "Epoch 5/5000\n",
            "526/526 - 2s - loss: 0.0896 - type_loss: 0.0414 - classification_loss: 0.0482 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9818 - val_loss: 0.1233 - val_type_loss: 0.0765 - val_classification_loss: 0.0468 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9832\n",
            "Epoch 6/5000\n",
            "526/526 - 2s - loss: 0.0836 - type_loss: 0.0409 - classification_loss: 0.0426 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9838 - val_loss: 0.1155 - val_type_loss: 0.0765 - val_classification_loss: 0.0390 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9862\n",
            "Epoch 7/5000\n",
            "526/526 - 2s - loss: 0.0787 - type_loss: 0.0401 - classification_loss: 0.0386 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9854 - val_loss: 0.1111 - val_type_loss: 0.0765 - val_classification_loss: 0.0347 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9871\n",
            "Epoch 8/5000\n",
            "526/526 - 2s - loss: 0.0757 - type_loss: 0.0409 - classification_loss: 0.0348 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9868 - val_loss: 0.1121 - val_type_loss: 0.0765 - val_classification_loss: 0.0356 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9873\n",
            "Epoch 9/5000\n",
            "526/526 - 2s - loss: 0.0733 - type_loss: 0.0408 - classification_loss: 0.0325 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9877 - val_loss: 0.1093 - val_type_loss: 0.0765 - val_classification_loss: 0.0329 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9878\n",
            "Epoch 10/5000\n",
            "526/526 - 2s - loss: 0.0724 - type_loss: 0.0412 - classification_loss: 0.0312 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9882 - val_loss: 0.1049 - val_type_loss: 0.0765 - val_classification_loss: 0.0284 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9897\n",
            "Epoch 11/5000\n",
            "526/526 - 2s - loss: 0.0702 - type_loss: 0.0411 - classification_loss: 0.0291 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9890 - val_loss: 0.1020 - val_type_loss: 0.0765 - val_classification_loss: 0.0255 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9905\n",
            "Epoch 12/5000\n",
            "526/526 - 2s - loss: 0.0675 - type_loss: 0.0403 - classification_loss: 0.0272 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9897 - val_loss: 0.1039 - val_type_loss: 0.0765 - val_classification_loss: 0.0275 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9897\n",
            "Epoch 13/5000\n",
            "526/526 - 2s - loss: 0.0668 - type_loss: 0.0406 - classification_loss: 0.0261 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9900 - val_loss: 0.1041 - val_type_loss: 0.0765 - val_classification_loss: 0.0276 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9896\n",
            "Epoch 14/5000\n",
            "526/526 - 2s - loss: 0.0655 - type_loss: 0.0408 - classification_loss: 0.0247 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9906 - val_loss: 0.1016 - val_type_loss: 0.0765 - val_classification_loss: 0.0251 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9908\n",
            "Epoch 15/5000\n",
            "526/526 - 2s - loss: 0.0649 - type_loss: 0.0410 - classification_loss: 0.0238 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9910 - val_loss: 0.1042 - val_type_loss: 0.0765 - val_classification_loss: 0.0277 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9899\n",
            "Epoch 16/5000\n",
            "526/526 - 2s - loss: 0.0632 - type_loss: 0.0401 - classification_loss: 0.0232 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9912 - val_loss: 0.1049 - val_type_loss: 0.0765 - val_classification_loss: 0.0284 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9902\n",
            "Epoch 17/5000\n",
            "526/526 - 2s - loss: 0.0636 - type_loss: 0.0418 - classification_loss: 0.0217 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9917 - val_loss: 0.0989 - val_type_loss: 0.0765 - val_classification_loss: 0.0224 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9919\n",
            "Epoch 18/5000\n",
            "526/526 - 2s - loss: 0.0613 - type_loss: 0.0402 - classification_loss: 0.0211 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9919 - val_loss: 0.0966 - val_type_loss: 0.0765 - val_classification_loss: 0.0201 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9923\n",
            "Epoch 19/5000\n",
            "526/526 - 2s - loss: 0.0618 - type_loss: 0.0406 - classification_loss: 0.0212 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9919 - val_loss: 0.1004 - val_type_loss: 0.0765 - val_classification_loss: 0.0239 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9916\n",
            "Epoch 20/5000\n",
            "526/526 - 2s - loss: 0.0614 - type_loss: 0.0406 - classification_loss: 0.0208 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9921 - val_loss: 0.0970 - val_type_loss: 0.0765 - val_classification_loss: 0.0205 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9918\n",
            "Epoch 21/5000\n",
            "526/526 - 2s - loss: 0.0609 - type_loss: 0.0416 - classification_loss: 0.0194 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9926 - val_loss: 0.1034 - val_type_loss: 0.0765 - val_classification_loss: 0.0269 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9908\n",
            "Epoch 22/5000\n",
            "526/526 - 2s - loss: 0.0604 - type_loss: 0.0416 - classification_loss: 0.0188 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9928 - val_loss: 0.0966 - val_type_loss: 0.0765 - val_classification_loss: 0.0201 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9926\n",
            "Epoch 23/5000\n",
            "526/526 - 2s - loss: 0.0588 - type_loss: 0.0403 - classification_loss: 0.0185 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9930 - val_loss: 0.0934 - val_type_loss: 0.0765 - val_classification_loss: 0.0169 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9936\n",
            "Epoch 24/5000\n",
            "526/526 - 2s - loss: 0.0603 - type_loss: 0.0420 - classification_loss: 0.0182 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9931 - val_loss: 0.1028 - val_type_loss: 0.0765 - val_classification_loss: 0.0263 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9911\n",
            "Epoch 25/5000\n",
            "526/526 - 2s - loss: 0.0584 - type_loss: 0.0411 - classification_loss: 0.0173 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9934 - val_loss: 0.1024 - val_type_loss: 0.0765 - val_classification_loss: 0.0259 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9913\n",
            "Epoch 26/5000\n",
            "526/526 - 2s - loss: 0.0566 - type_loss: 0.0396 - classification_loss: 0.0170 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9935 - val_loss: 0.0967 - val_type_loss: 0.0765 - val_classification_loss: 0.0202 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9931\n",
            "Epoch 27/5000\n",
            "526/526 - 2s - loss: 0.0575 - type_loss: 0.0403 - classification_loss: 0.0171 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9935 - val_loss: 0.0955 - val_type_loss: 0.0765 - val_classification_loss: 0.0190 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9929\n",
            "Epoch 28/5000\n",
            "526/526 - 2s - loss: 0.0574 - type_loss: 0.0403 - classification_loss: 0.0171 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9935 - val_loss: 0.0994 - val_type_loss: 0.0765 - val_classification_loss: 0.0229 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9920\n",
            "Epoch 29/5000\n",
            "526/526 - 2s - loss: 0.0565 - type_loss: 0.0409 - classification_loss: 0.0156 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9941 - val_loss: 0.0969 - val_type_loss: 0.0765 - val_classification_loss: 0.0205 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9933\n",
            "Epoch 30/5000\n",
            "526/526 - 2s - loss: 0.0558 - type_loss: 0.0401 - classification_loss: 0.0157 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.9940 - val_loss: 0.0956 - val_type_loss: 0.0765 - val_classification_loss: 0.0191 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9931\n",
            "Epoch 31/5000\n",
            "526/526 - 2s - loss: 0.0559 - type_loss: 0.0409 - classification_loss: 0.0150 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9944 - val_loss: 0.0939 - val_type_loss: 0.0765 - val_classification_loss: 0.0174 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9940\n",
            "Epoch 32/5000\n",
            "526/526 - 2s - loss: 0.0564 - type_loss: 0.0404 - classification_loss: 0.0160 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9939 - val_loss: 0.0987 - val_type_loss: 0.0765 - val_classification_loss: 0.0222 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9933\n",
            "Epoch 33/5000\n",
            "526/526 - 2s - loss: 0.0541 - type_loss: 0.0391 - classification_loss: 0.0150 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9943 - val_loss: 0.0962 - val_type_loss: 0.0765 - val_classification_loss: 0.0197 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9935\n",
            "Epoch 34/5000\n",
            "526/526 - 3s - loss: 0.0557 - type_loss: 0.0411 - classification_loss: 0.0145 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9945 - val_loss: 0.0945 - val_type_loss: 0.0765 - val_classification_loss: 0.0180 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9939\n",
            "Epoch 35/5000\n",
            "526/526 - 3s - loss: 0.0556 - type_loss: 0.0414 - classification_loss: 0.0142 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9946 - val_loss: 0.0951 - val_type_loss: 0.0765 - val_classification_loss: 0.0187 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9926\n",
            "Epoch 36/5000\n",
            "526/526 - 2s - loss: 0.0556 - type_loss: 0.0413 - classification_loss: 0.0143 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9945 - val_loss: 0.0954 - val_type_loss: 0.0765 - val_classification_loss: 0.0189 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9937\n",
            "Epoch 37/5000\n",
            "526/526 - 2s - loss: 0.0548 - type_loss: 0.0409 - classification_loss: 0.0139 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9947 - val_loss: 0.0910 - val_type_loss: 0.0765 - val_classification_loss: 0.0145 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9948\n",
            "Epoch 38/5000\n",
            "526/526 - 2s - loss: 0.0541 - type_loss: 0.0405 - classification_loss: 0.0136 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9949 - val_loss: 0.0971 - val_type_loss: 0.0765 - val_classification_loss: 0.0206 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9936\n",
            "Epoch 39/5000\n",
            "526/526 - 2s - loss: 0.0531 - type_loss: 0.0399 - classification_loss: 0.0132 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9950 - val_loss: 0.0968 - val_type_loss: 0.0765 - val_classification_loss: 0.0204 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9936\n",
            "Epoch 40/5000\n",
            "526/526 - 2s - loss: 0.0536 - type_loss: 0.0400 - classification_loss: 0.0136 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.9949 - val_loss: 0.0944 - val_type_loss: 0.0765 - val_classification_loss: 0.0179 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9940\n",
            "Epoch 41/5000\n",
            "526/526 - 2s - loss: 0.0540 - type_loss: 0.0409 - classification_loss: 0.0131 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9950 - val_loss: 0.0947 - val_type_loss: 0.0765 - val_classification_loss: 0.0183 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9936\n",
            "Epoch 42/5000\n",
            "526/526 - 2s - loss: 0.0544 - type_loss: 0.0413 - classification_loss: 0.0131 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9951 - val_loss: 0.0893 - val_type_loss: 0.0765 - val_classification_loss: 0.0128 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9950\n",
            "Epoch 43/5000\n",
            "526/526 - 2s - loss: 0.0527 - type_loss: 0.0396 - classification_loss: 0.0131 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9951 - val_loss: 0.0911 - val_type_loss: 0.0765 - val_classification_loss: 0.0146 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9946\n",
            "Epoch 44/5000\n",
            "526/526 - 2s - loss: 0.0522 - type_loss: 0.0398 - classification_loss: 0.0123 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9953 - val_loss: 0.1018 - val_type_loss: 0.0765 - val_classification_loss: 0.0253 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9927\n",
            "Epoch 45/5000\n",
            "526/526 - 2s - loss: 0.0538 - type_loss: 0.0406 - classification_loss: 0.0132 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9951 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0185 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9944\n",
            "Epoch 46/5000\n",
            "526/526 - 2s - loss: 0.0532 - type_loss: 0.0408 - classification_loss: 0.0125 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9953 - val_loss: 0.0981 - val_type_loss: 0.0765 - val_classification_loss: 0.0217 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9933\n",
            "Epoch 47/5000\n",
            "526/526 - 2s - loss: 0.0535 - type_loss: 0.0413 - classification_loss: 0.0122 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9954 - val_loss: 0.0948 - val_type_loss: 0.0765 - val_classification_loss: 0.0183 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9939\n",
            "Epoch 48/5000\n",
            "526/526 - 2s - loss: 0.0528 - type_loss: 0.0409 - classification_loss: 0.0119 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9955 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0185 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9939\n",
            "Epoch 49/5000\n",
            "526/526 - 2s - loss: 0.0533 - type_loss: 0.0410 - classification_loss: 0.0123 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9954 - val_loss: 0.0951 - val_type_loss: 0.0765 - val_classification_loss: 0.0186 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9943\n",
            "Epoch 50/5000\n",
            "526/526 - 2s - loss: 0.0528 - type_loss: 0.0410 - classification_loss: 0.0119 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9955 - val_loss: 0.0949 - val_type_loss: 0.0765 - val_classification_loss: 0.0184 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9943\n",
            "Epoch 51/5000\n",
            "526/526 - 2s - loss: 0.0523 - type_loss: 0.0408 - classification_loss: 0.0116 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.9956 - val_loss: 0.0941 - val_type_loss: 0.0765 - val_classification_loss: 0.0176 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9945\n",
            "Epoch 52/5000\n",
            "526/526 - 2s - loss: 0.0519 - type_loss: 0.0403 - classification_loss: 0.0116 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9956 - val_loss: 0.0923 - val_type_loss: 0.0765 - val_classification_loss: 0.0159 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9948\n",
            "Epoch 53/5000\n",
            "526/526 - 2s - loss: 0.0516 - type_loss: 0.0402 - classification_loss: 0.0114 - type_categorical_accuracy: 0.9871 - classification_binary_accuracy: 0.9957 - val_loss: 0.0991 - val_type_loss: 0.0765 - val_classification_loss: 0.0227 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9931\n",
            "Epoch 54/5000\n",
            "526/526 - 2s - loss: 0.0528 - type_loss: 0.0413 - classification_loss: 0.0115 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9956 - val_loss: 0.0976 - val_type_loss: 0.0765 - val_classification_loss: 0.0211 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9941\n",
            "Epoch 55/5000\n",
            "526/526 - 2s - loss: 0.0525 - type_loss: 0.0411 - classification_loss: 0.0113 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9956 - val_loss: 0.0968 - val_type_loss: 0.0765 - val_classification_loss: 0.0203 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9942\n",
            "Epoch 56/5000\n",
            "526/526 - 2s - loss: 0.0525 - type_loss: 0.0415 - classification_loss: 0.0110 - type_categorical_accuracy: 0.9862 - classification_binary_accuracy: 0.9959 - val_loss: 0.0912 - val_type_loss: 0.0765 - val_classification_loss: 0.0147 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9950\n",
            "Epoch 57/5000\n",
            "526/526 - 2s - loss: 0.0526 - type_loss: 0.0416 - classification_loss: 0.0110 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9958 - val_loss: 0.0962 - val_type_loss: 0.0765 - val_classification_loss: 0.0197 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9942\n",
            "Epoch 58/5000\n",
            "526/526 - 2s - loss: 0.0528 - type_loss: 0.0419 - classification_loss: 0.0109 - type_categorical_accuracy: 0.9861 - classification_binary_accuracy: 0.9958 - val_loss: 0.1004 - val_type_loss: 0.0765 - val_classification_loss: 0.0239 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9936\n",
            "Epoch 59/5000\n",
            "526/526 - 2s - loss: 0.0519 - type_loss: 0.0408 - classification_loss: 0.0111 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9959 - val_loss: 0.0966 - val_type_loss: 0.0765 - val_classification_loss: 0.0201 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9943\n",
            "Epoch 60/5000\n",
            "526/526 - 2s - loss: 0.0510 - type_loss: 0.0404 - classification_loss: 0.0106 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9959 - val_loss: 0.0946 - val_type_loss: 0.0765 - val_classification_loss: 0.0181 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9945\n",
            "Epoch 61/5000\n",
            "526/526 - 2s - loss: 0.0515 - type_loss: 0.0409 - classification_loss: 0.0106 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9960 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0185 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9946\n",
            "Epoch 62/5000\n",
            "526/526 - 2s - loss: 0.0512 - type_loss: 0.0403 - classification_loss: 0.0109 - type_categorical_accuracy: 0.9871 - classification_binary_accuracy: 0.9959 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0186 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9944\n",
            "Epoch 63/5000\n",
            "526/526 - 2s - loss: 0.0515 - type_loss: 0.0411 - classification_loss: 0.0104 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9961 - val_loss: 0.0938 - val_type_loss: 0.0765 - val_classification_loss: 0.0174 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9947\n",
            "Epoch 64/5000\n",
            "526/526 - 2s - loss: 0.0519 - type_loss: 0.0416 - classification_loss: 0.0103 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9961 - val_loss: 0.1002 - val_type_loss: 0.0765 - val_classification_loss: 0.0237 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9935\n",
            "Epoch 65/5000\n",
            "526/526 - 2s - loss: 0.0516 - type_loss: 0.0410 - classification_loss: 0.0106 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9960 - val_loss: 0.0926 - val_type_loss: 0.0765 - val_classification_loss: 0.0162 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9950\n",
            "Epoch 66/5000\n",
            "526/526 - 2s - loss: 0.0510 - type_loss: 0.0408 - classification_loss: 0.0102 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9961 - val_loss: 0.0961 - val_type_loss: 0.0765 - val_classification_loss: 0.0196 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9945\n",
            "Epoch 67/5000\n",
            "526/526 - 2s - loss: 0.0518 - type_loss: 0.0417 - classification_loss: 0.0101 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9962 - val_loss: 0.0918 - val_type_loss: 0.0765 - val_classification_loss: 0.0153 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9953\n",
            "Epoch 68/5000\n",
            "526/526 - 2s - loss: 0.0513 - type_loss: 0.0413 - classification_loss: 0.0100 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9962 - val_loss: 0.1008 - val_type_loss: 0.0765 - val_classification_loss: 0.0243 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9941\n",
            "Epoch 69/5000\n",
            "526/526 - 2s - loss: 0.0506 - type_loss: 0.0405 - classification_loss: 0.0101 - type_categorical_accuracy: 0.9863 - classification_binary_accuracy: 0.9962 - val_loss: 0.0924 - val_type_loss: 0.0765 - val_classification_loss: 0.0159 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9947\n",
            "Epoch 70/5000\n",
            "526/526 - 2s - loss: 0.0498 - type_loss: 0.0398 - classification_loss: 0.0101 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9962 - val_loss: 0.0953 - val_type_loss: 0.0765 - val_classification_loss: 0.0188 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9947\n",
            "Epoch 71/5000\n",
            "526/526 - 2s - loss: 0.0512 - type_loss: 0.0412 - classification_loss: 0.0100 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9962 - val_loss: 0.0971 - val_type_loss: 0.0765 - val_classification_loss: 0.0206 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9941\n",
            "Epoch 72/5000\n",
            "526/526 - 2s - loss: 0.0505 - type_loss: 0.0408 - classification_loss: 0.0097 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9963 - val_loss: 0.0954 - val_type_loss: 0.0765 - val_classification_loss: 0.0189 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9945\n",
            "Epoch 73/5000\n",
            "526/526 - 2s - loss: 0.0514 - type_loss: 0.0415 - classification_loss: 0.0099 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9963 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0185 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9950\n",
            "Epoch 74/5000\n",
            "526/526 - 2s - loss: 0.0501 - type_loss: 0.0407 - classification_loss: 0.0094 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9965 - val_loss: 0.0959 - val_type_loss: 0.0765 - val_classification_loss: 0.0194 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9946\n",
            "Epoch 75/5000\n",
            "526/526 - 2s - loss: 0.0508 - type_loss: 0.0410 - classification_loss: 0.0097 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9964 - val_loss: 0.0935 - val_type_loss: 0.0765 - val_classification_loss: 0.0171 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9947\n",
            "Epoch 76/5000\n",
            "526/526 - 2s - loss: 0.0500 - type_loss: 0.0403 - classification_loss: 0.0097 - type_categorical_accuracy: 0.9872 - classification_binary_accuracy: 0.9964 - val_loss: 0.0984 - val_type_loss: 0.0765 - val_classification_loss: 0.0219 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9946\n",
            "Epoch 77/5000\n",
            "526/526 - 2s - loss: 0.0506 - type_loss: 0.0410 - classification_loss: 0.0097 - type_categorical_accuracy: 0.9871 - classification_binary_accuracy: 0.9963 - val_loss: 0.0950 - val_type_loss: 0.0765 - val_classification_loss: 0.0185 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9944\n",
            "Epoch 78/5000\n",
            "526/526 - 2s - loss: 0.0502 - type_loss: 0.0412 - classification_loss: 0.0090 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9966 - val_loss: 0.0965 - val_type_loss: 0.0765 - val_classification_loss: 0.0200 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9949\n",
            "Epoch 79/5000\n",
            "526/526 - 2s - loss: 0.0498 - type_loss: 0.0401 - classification_loss: 0.0097 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9963 - val_loss: 0.1006 - val_type_loss: 0.0765 - val_classification_loss: 0.0242 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9941\n",
            "Epoch 80/5000\n",
            "526/526 - 2s - loss: 0.0507 - type_loss: 0.0414 - classification_loss: 0.0094 - type_categorical_accuracy: 0.9865 - classification_binary_accuracy: 0.9965 - val_loss: 0.0935 - val_type_loss: 0.0765 - val_classification_loss: 0.0170 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9951\n",
            "Epoch 81/5000\n",
            "526/526 - 2s - loss: 0.0504 - type_loss: 0.0414 - classification_loss: 0.0090 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9966 - val_loss: 0.0974 - val_type_loss: 0.0765 - val_classification_loss: 0.0209 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9943\n",
            "Epoch 82/5000\n",
            "526/526 - 2s - loss: 0.0497 - type_loss: 0.0410 - classification_loss: 0.0087 - type_categorical_accuracy: 0.9864 - classification_binary_accuracy: 0.9967 - val_loss: 0.1031 - val_type_loss: 0.0765 - val_classification_loss: 0.0266 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9938\n",
            "Epoch 83/5000\n",
            "526/526 - 2s - loss: 0.0498 - type_loss: 0.0403 - classification_loss: 0.0095 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9964 - val_loss: 0.0946 - val_type_loss: 0.0765 - val_classification_loss: 0.0181 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9949\n",
            "Epoch 84/5000\n",
            "526/526 - 2s - loss: 0.0497 - type_loss: 0.0403 - classification_loss: 0.0094 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9965 - val_loss: 0.0935 - val_type_loss: 0.0765 - val_classification_loss: 0.0170 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9952\n",
            "Epoch 85/5000\n",
            "526/526 - 2s - loss: 0.0496 - type_loss: 0.0405 - classification_loss: 0.0091 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9965 - val_loss: 0.0902 - val_type_loss: 0.0765 - val_classification_loss: 0.0137 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9958\n",
            "Epoch 86/5000\n",
            "526/526 - 2s - loss: 0.0492 - type_loss: 0.0401 - classification_loss: 0.0091 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9966 - val_loss: 0.0936 - val_type_loss: 0.0765 - val_classification_loss: 0.0171 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9953\n",
            "Epoch 87/5000\n",
            "526/526 - 2s - loss: 0.0508 - type_loss: 0.0413 - classification_loss: 0.0095 - type_categorical_accuracy: 0.9866 - classification_binary_accuracy: 0.9965 - val_loss: 0.0893 - val_type_loss: 0.0765 - val_classification_loss: 0.0128 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9958\n",
            "Epoch 88/5000\n",
            "526/526 - 2s - loss: 0.0487 - type_loss: 0.0399 - classification_loss: 0.0088 - type_categorical_accuracy: 0.9871 - classification_binary_accuracy: 0.9967 - val_loss: 0.0980 - val_type_loss: 0.0765 - val_classification_loss: 0.0215 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9947\n",
            "Epoch 89/5000\n",
            "526/526 - 2s - loss: 0.0483 - type_loss: 0.0398 - classification_loss: 0.0085 - type_categorical_accuracy: 0.9868 - classification_binary_accuracy: 0.9968 - val_loss: 0.0992 - val_type_loss: 0.0765 - val_classification_loss: 0.0228 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9945\n",
            "Epoch 90/5000\n",
            "526/526 - 2s - loss: 0.0496 - type_loss: 0.0408 - classification_loss: 0.0088 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9967 - val_loss: 0.1028 - val_type_loss: 0.0765 - val_classification_loss: 0.0264 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9939\n",
            "Epoch 91/5000\n",
            "526/526 - 2s - loss: 0.0491 - type_loss: 0.0403 - classification_loss: 0.0088 - type_categorical_accuracy: 0.9869 - classification_binary_accuracy: 0.9967 - val_loss: 0.0930 - val_type_loss: 0.0765 - val_classification_loss: 0.0165 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9948\n",
            "Epoch 92/5000\n",
            "526/526 - 2s - loss: 0.0490 - type_loss: 0.0402 - classification_loss: 0.0088 - type_categorical_accuracy: 0.9867 - classification_binary_accuracy: 0.9967 - val_loss: 0.0971 - val_type_loss: 0.0765 - val_classification_loss: 0.0206 - val_type_categorical_accuracy: 0.9791 - val_classification_binary_accuracy: 0.9946\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00092: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento antigo (Usado com as CNNs)"
      ],
      "metadata": {
        "id": "7pOs_nEhY7e0"
      }
    }
  ]
}